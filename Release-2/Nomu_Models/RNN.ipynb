{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d48249-8d84-4320-b6b1-1ac79f07f185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (98200, 20, 1) (98200,)\n",
      "Test : (24600, 20, 1) (24600,)\n",
      "Test changes from file: (24600,)\n",
      "Epoch 1/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - loss: 0.0296 - val_loss: 0.1453\n",
      "Epoch 2/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - loss: 0.0104 - val_loss: 0.1109\n",
      "Epoch 3/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - loss: 0.0093 - val_loss: 0.0918\n",
      "Epoch 4/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - loss: 0.0091 - val_loss: 0.0870\n",
      "Epoch 5/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - loss: 0.0089 - val_loss: 0.0793\n",
      "Epoch 6/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - loss: 0.0090 - val_loss: 0.0670\n",
      "Epoch 7/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - loss: 0.0088 - val_loss: 0.0829\n",
      "Epoch 8/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - loss: 0.0087 - val_loss: 0.0750\n",
      "Epoch 9/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - loss: 0.0087 - val_loss: 0.0931\n",
      "Epoch 10/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - loss: 0.0087 - val_loss: 0.0812\n",
      "Epoch 11/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - loss: 0.0086 - val_loss: 0.0587\n",
      "Epoch 12/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - loss: 0.0086 - val_loss: 0.0657\n",
      "\n",
      "=== Global Test Metrics (Close Level) ===\n",
      "R²   = 0.9963\n",
      "MAE  = 0.7915\n",
      "RMSE = 2.5921\n",
      "\n",
      "=== Change (Δ Close) Metrics — Derived from Close ===\n",
      "R² (Δ from price)   = -4.0112\n",
      "MAE (Δ from price)  = 0.7915\n",
      "RMSE (Δ from price) = 2.5921\n",
      "\n",
      "=== Change Metrics — From clean.csv (عمود 'التغيير') ===\n",
      "R² (clean.csv)   = -5.6879\n",
      "MAE (clean.csv)  = 0.853873\n",
      "RMSE (clean.csv) = 2.870464\n",
      "\n",
      "=== Change Percentage Metrics (filtered, from price) ===\n",
      "R² (Δ%)   = -0.9426\n",
      "MAE (Δ%)  = 0.015073\n",
      "RMSE (Δ%) = 0.024658\n",
      "sMAPE (Δ) = 1.514477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample predictions with recommendations:\n",
      "                                اسم الشركة  yesterday   predicted  \\\n",
      "0                 اعمار المدينة الاقتصادية      17.23   17.239176   \n",
      "1                     البنك الاهلي السعودي      38.65   38.843105   \n",
      "2                      البنك السعودي الاول      37.90   37.915913   \n",
      "3                    البنك السعودي الفرنسي      19.30   19.335321   \n",
      "4                  البنك السعودي للاستثمار      12.76   12.737811   \n",
      "5                      البنك العربي الوطني      18.97   18.989807   \n",
      "6                 الشركة التعاونية للتامين     130.20  107.352341   \n",
      "7  الشركة الخليجية العامة للتامين التعاوني      13.17   13.272333   \n",
      "8           الشركة السعودية لاعادة التامين      18.60   18.531908   \n",
      "9            الشركة السعودية لانابيب الصلب      36.30   35.977356   \n",
      "\n",
      "  recommendation  \n",
      "0      Don’t Buy  \n",
      "1      Don’t Buy  \n",
      "2      Don’t Buy  \n",
      "3      Don’t Buy  \n",
      "4            Buy  \n",
      "5      Don’t Buy  \n",
      "6            Buy  \n",
      "7      Don’t Buy  \n",
      "8            Buy  \n",
      "9            Buy  \n",
      "✅ Saved model: out\\rnn_model_with_norm.h5\n",
      "✅ Saved recommendations: out\\rnn_recommendations.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "\n",
    "# -------- إعدادات --------\n",
    "WIDE_PATH   = \"Equites_Close_Daily.csv\"   # ملف wide (كل عمود = يوم، الصف = شركة)\n",
    "CHANGE_PATH = \"clean.csv\"                 # ملف طويل يحتوي عمود \"التغيير\"\n",
    "WINDOW_LEN  = 20\n",
    "TRAIN_RATIO = 0.8\n",
    "EPOCHS      = 12\n",
    "BATCH_SIZE  = 128\n",
    "\n",
    "# -------- دوال --------\n",
    "def build_sequences_with_idx(series_vals, window):\n",
    "    \"\"\"\n",
    "    يبني تسلسلات الإدخال والإخراج ويُرجع أيضًا فهارس الأهداف (t) التي تم الاحتفاظ بها،\n",
    "    حتى نربطها لاحقًا بقيم التغير بحسب التاريخ.\n",
    "    \"\"\"\n",
    "    X, y, kept_idx = [], [], []\n",
    "    for t in range(window, len(series_vals)):\n",
    "        feat = series_vals[t-window:t]\n",
    "        target = series_vals[t]\n",
    "        if np.isnan(feat).any() or np.isnan(target):\n",
    "            continue\n",
    "        X.append(feat)\n",
    "        y.append(target)\n",
    "        kept_idx.append(t)\n",
    "    if not X:\n",
    "        return np.empty((0, window, 1), dtype=\"float32\"), np.empty((0,), dtype=\"float32\"), np.array([], dtype=int)\n",
    "    X = np.array(X, dtype=\"float32\")[:, :, None]\n",
    "    y = np.array(y, dtype=\"float32\")\n",
    "    return X, y, np.array(kept_idx, dtype=int)\n",
    "\n",
    "# -------- تحميل wide (إغلاقات) --------\n",
    "wide = pd.read_csv(WIDE_PATH, encoding=\"utf-8-sig\").set_index(\"اسم الشركة\")\n",
    "# تحويل القيم لأرقام\n",
    "wide = wide.apply(pd.to_numeric, errors=\"coerce\")\n",
    "# توحيد تنسيق أعمدة التواريخ لصيغة YYYY-MM-DD\n",
    "wide_cols_dt = pd.to_datetime(wide.columns, errors=\"coerce\")\n",
    "wide.columns = wide_cols_dt.strftime(\"%Y-%m-%d\")\n",
    "date_cols = list(wide.columns)\n",
    "\n",
    "# -------- تحميل clean.csv (طويل) وأخذ عمود \"التغيير\" --------\n",
    "change_long = pd.read_csv(CHANGE_PATH, encoding=\"utf-8-sig\")\n",
    "\n",
    "col_company = \"اسم الشركة\"\n",
    "col_date    = \"التاريخ\"\n",
    "col_change  = \"التغيير\"       # <-- التعديل هنا\n",
    "\n",
    "# التحقق من الأعمدة\n",
    "for c in [col_company, col_date, col_change]:\n",
    "    if c not in change_long.columns:\n",
    "        raise ValueError(f\"عمود '{c}' غير موجود في clean.csv. الأعمدة المتاحة: {list(change_long.columns)}\")\n",
    "\n",
    "# تجهيز التواريخ والقيم\n",
    "change_long[col_date] = pd.to_datetime(change_long[col_date], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
    "change_long[col_change] = pd.to_numeric(change_long[col_change], errors=\"coerce\")\n",
    "\n",
    "# قاموس lookup: شركة -> {تاريخ: تغيير}\n",
    "change_maps = {}\n",
    "for comp, dfc in change_long.groupby(col_company):\n",
    "    ser = (\n",
    "        dfc.dropna(subset=[col_date])[[col_date, col_change]]\n",
    "           .dropna()\n",
    "           .drop_duplicates(subset=[col_date])\n",
    "           .set_index(col_date)[col_change]\n",
    "    )\n",
    "    change_maps[comp] = ser.to_dict()\n",
    "\n",
    "# -------- إعداد بيانات التدريب --------\n",
    "X_tr_list, y_tr_list = [], []\n",
    "X_te_list, y_te_list = [], []\n",
    "te_mu_list, te_sigma_list = [], []\n",
    "y_change_te_list = []      # لتقييم التغير من clean.csv بمحاذاة X_test\n",
    "next_day_preds = []\n",
    "\n",
    "for comp, row in wide.iterrows():\n",
    "    vals = row.values.astype(\"float64\")\n",
    "    if np.sum(~np.isnan(vals)) < WINDOW_LEN + 2:\n",
    "        continue\n",
    "\n",
    "    X_all, y_all, kept_idx = build_sequences_with_idx(vals, WINDOW_LEN)\n",
    "    if len(y_all) < 3:\n",
    "        continue\n",
    "\n",
    "    split = max(1, int(len(y_all) * TRAIN_RATIO))\n",
    "    X_tr_c, y_tr_c = X_all[:split], y_all[:split]\n",
    "    X_te_c, y_te_c = X_all[split:], y_all[split:]\n",
    "    kept_idx_te = kept_idx[split:]\n",
    "\n",
    "    if len(y_te_c) == 0:\n",
    "        continue\n",
    "\n",
    "    # تطبيع بناءً على train\n",
    "    train_series_vals = np.concatenate([X_tr_c.reshape(-1), y_tr_c.reshape(-1)])\n",
    "    mu = np.nanmean(train_series_vals)\n",
    "    sigma = np.nanstd(train_series_vals)\n",
    "    if not np.isfinite(mu) or sigma <= 1e-12:\n",
    "        continue\n",
    "\n",
    "    X_tr_c_norm = (X_tr_c - mu) / sigma\n",
    "    y_tr_c_norm = (y_tr_c - mu) / sigma\n",
    "    X_te_c_norm = (X_te_c - mu) / sigma\n",
    "    y_te_c_norm = (y_te_c - mu) / sigma\n",
    "\n",
    "    X_tr_list.append(X_tr_c_norm)\n",
    "    y_tr_list.append(y_tr_c_norm)\n",
    "    X_te_list.append(X_te_c_norm)\n",
    "    y_te_list.append(y_te_c_norm)\n",
    "\n",
    "    te_mu_list  += [mu] * len(y_te_c_norm)\n",
    "    te_sigma_list += [sigma] * len(y_te_c_norm)\n",
    "\n",
    "    # جلب قيم \"التغيير\" من clean.csv لنفس أيام الاختبار\n",
    "    if comp in change_maps:\n",
    "        mp = change_maps[comp]\n",
    "        y_change_all = np.array([mp.get(date_cols[t], np.nan) for t in kept_idx], dtype=\"float64\")\n",
    "        y_change_te_list.append(y_change_all[split:])\n",
    "    else:\n",
    "        y_change_te_list.append(np.full(len(y_te_c), np.nan, dtype=\"float64\"))\n",
    "\n",
    "    # نافذة اليوم التالي\n",
    "    last_window_raw = vals[-WINDOW_LEN:]\n",
    "    if np.isnan(last_window_raw).any():\n",
    "        next_day_preds.append({\"اسم الشركة\": comp, \"next_day_pred\": np.nan})\n",
    "    else:\n",
    "        last_window_norm = ((last_window_raw - mu) / sigma).astype(\"float32\").reshape(1, WINDOW_LEN, 1)\n",
    "        next_day_preds.append({\n",
    "            \"اسم الشركة\": comp,\n",
    "            \"last_window_norm\": last_window_norm,\n",
    "            \"mu\": mu,\n",
    "            \"sigma\": sigma,\n",
    "            \"yesterday\": last_window_raw[-1]\n",
    "        })\n",
    "\n",
    "# دمج جميع الشركات\n",
    "X_train = np.concatenate(X_tr_list, axis=0)\n",
    "y_train = np.concatenate(y_tr_list, axis=0)\n",
    "X_test  = np.concatenate(X_te_list, axis=0)\n",
    "y_test  = np.concatenate(y_te_list, axis=0)\n",
    "te_mu   = np.array(te_mu_list, dtype=\"float64\")\n",
    "te_sig  = np.array(te_sigma_list, dtype=\"float64\")\n",
    "y_change_test_from_file = np.concatenate(y_change_te_list, axis=0) if y_change_te_list else np.array([], dtype=\"float64\")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test :\", X_test.shape,  y_test.shape)\n",
    "print(\"Test changes from file:\", y_change_test_from_file.shape)\n",
    "\n",
    "# -------- RNN --------\n",
    "tf.keras.backend.clear_session()\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(WINDOW_LEN, 1)),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.LSTM(32),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# -------- تقييم (على السعر) --------\n",
    "y_hat_norm = model.predict(X_test, verbose=0).reshape(-1)\n",
    "y_hat = y_hat_norm * te_sig + te_mu\n",
    "y_true = y_test * te_sig + te_mu\n",
    "\n",
    "R2   = r2_score(y_true, y_hat)\n",
    "MAE  = mean_absolute_error(y_true, y_hat)\n",
    "RMSE = float(np.sqrt(mean_squared_error(y_true, y_hat)))\n",
    "\n",
    "print(\"\\n=== Global Test Metrics (Close Level) ===\")\n",
    "print(f\"R²   = {R2:.4f}\")\n",
    "print(f\"MAE  = {MAE:.4f}\")\n",
    "print(f\"RMSE = {RMSE:.4f}\")\n",
    "\n",
    "# -------- التغير (Δ) المُشتق من السعر (مرجعي) --------\n",
    "prev_close = (X_test[:, -1, 0] * te_sig + te_mu)\n",
    "true_change_from_price = y_true - prev_close\n",
    "pred_change_from_price = y_hat  - prev_close\n",
    "\n",
    "R2_change_price   = r2_score(true_change_from_price, pred_change_from_price)\n",
    "MAE_change_price  = mean_absolute_error(true_change_from_price, pred_change_from_price)\n",
    "RMSE_change_price = float(np.sqrt(mean_squared_error(true_change_from_price, pred_change_from_price)))\n",
    "\n",
    "print(\"\\n=== Change (Δ Close) Metrics — Derived from Close ===\")\n",
    "print(f\"R² (Δ from price)   = {R2_change_price:.4f}\")\n",
    "print(f\"MAE (Δ from price)  = {MAE_change_price:.4f}\")\n",
    "print(f\"RMSE (Δ from price) = {RMSE_change_price:.4f}\")\n",
    "\n",
    "# -------- تقييم على التغيير من clean.csv --------\n",
    "if y_change_test_from_file.size == X_test.shape[0]:\n",
    "    mask_file = np.isfinite(y_change_test_from_file) & np.isfinite(pred_change_from_price)\n",
    "    if mask_file.sum() > 0:\n",
    "        R2_change_file   = r2_score(y_change_test_from_file[mask_file], pred_change_from_price[mask_file])\n",
    "        MAE_change_file  = mean_absolute_error(y_change_test_from_file[mask_file], pred_change_from_price[mask_file])\n",
    "        RMSE_change_file = float(np.sqrt(mean_squared_error(y_change_test_from_file[mask_file], pred_change_from_price[mask_file])))\n",
    "\n",
    "        print(\"\\n=== Change Metrics — From clean.csv (عمود 'التغيير') ===\")\n",
    "        print(f\"R² (clean.csv)   = {R2_change_file:.4f}\")\n",
    "        print(f\"MAE (clean.csv)  = {MAE_change_file:.6f}\")\n",
    "        print(f\"RMSE (clean.csv) = {RMSE_change_file:.6f}\")\n",
    "    else:\n",
    "        print(\"\\n=== Change Metrics — From clean.csv ===\")\n",
    "        print(\"No valid samples after filtering NaNs/infs in clean.csv.\")\n",
    "else:\n",
    "    print(\"\\n[Warning] clean.csv alignment mismatch: \"\n",
    "          f\"len(test changes)={y_change_test_from_file.size} vs X_test={X_test.shape[0]}\")\n",
    "\n",
    "# -------- (اختياري) نسب تغير آمنة + sMAPE للتغير المُشتق من السعر --------\n",
    "eps = 1e-6\n",
    "valid_pct = np.isfinite(prev_close) & (np.abs(prev_close) > eps)\n",
    "true_change_pct = np.full_like(true_change_from_price, np.nan, dtype=\"float64\")\n",
    "pred_change_pct = np.full_like(pred_change_from_price, np.nan, dtype=\"float64\")\n",
    "true_change_pct[valid_pct] = true_change_from_price[valid_pct] / prev_close[valid_pct]\n",
    "pred_change_pct[valid_pct] = pred_change_from_price[valid_pct] / prev_close[valid_pct]\n",
    "\n",
    "mask_pct = np.isfinite(true_change_pct) & np.isfinite(pred_change_pct)\n",
    "if mask_pct.sum() > 0:\n",
    "    R2_change_pct   = r2_score(true_change_pct[mask_pct], pred_change_pct[mask_pct])\n",
    "    MAE_change_pct  = mean_absolute_error(true_change_pct[mask_pct], pred_change_pct[mask_pct])\n",
    "    RMSE_change_pct = float(np.sqrt(mean_squared_error(true_change_pct[mask_pct], pred_change_pct[mask_pct])))\n",
    "\n",
    "    smape = np.mean(\n",
    "        2.0 * np.abs(pred_change_from_price[mask_pct] - true_change_from_price[mask_pct]) /\n",
    "        (np.abs(pred_change_from_price[mask_pct]) + np.abs(true_change_from_price[mask_pct]) + eps)\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Change Percentage Metrics (filtered, from price) ===\")\n",
    "    print(f\"R² (Δ%)   = {R2_change_pct:.4f}\")\n",
    "    print(f\"MAE (Δ%)  = {MAE_change_pct:.6f}\")\n",
    "    print(f\"RMSE (Δ%) = {RMSE_change_pct:.6f}\")\n",
    "    print(f\"sMAPE (Δ) = {smape:.6f}\")\n",
    "else:\n",
    "    print(\"\\n=== Change Percentage Metrics (filtered, from price) ===\")\n",
    "    print(\"No valid samples for percentage metrics (prev_close too small/invalid).\")\n",
    "\n",
    "# -------- توقع + توصية --------\n",
    "pred_rows = []\n",
    "for rec in next_day_preds:\n",
    "    comp = rec[\"اسم الشركة\"]\n",
    "    if \"last_window_norm\" not in rec:\n",
    "        pred_rows.append({\"اسم الشركة\": comp, \"yesterday\": np.nan, \"predicted\": np.nan, \"recommendation\": \"N/A\"})\n",
    "        continue\n",
    "    pred_norm = model.predict(rec[\"last_window_norm\"], verbose=0).reshape(-1)[0]\n",
    "    pred = pred_norm * rec[\"sigma\"] + rec[\"mu\"]\n",
    "    yesterday = rec[\"yesterday\"]\n",
    "    recommendation = \"Buy\" if pred < yesterday else \"Don’t Buy\"\n",
    "    pred_rows.append({\n",
    "        \"اسم الشركة\": comp,\n",
    "        \"yesterday\": float(yesterday),\n",
    "        \"predicted\": float(pred),\n",
    "        \"recommendation\": recommendation\n",
    "    })\n",
    "\n",
    "pred_df = pd.DataFrame(pred_rows)\n",
    "print(\"\\nSample predictions with recommendations:\")\n",
    "print(pred_df.head(10))\n",
    "\n",
    "# -------- مجلد الحفظ --------\n",
    "OUT_DIR = \"out\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -------- حفظ الموديل --------\n",
    "model_path = os.path.join(OUT_DIR, \"rnn_model_with_norm.h5\")\n",
    "model.save(model_path)\n",
    "print(f\"✅ Saved model: {model_path}\")\n",
    "\n",
    "# -------- حفظ النتائج --------\n",
    "csv_path = os.path.join(OUT_DIR, \"rnn_recommendations.csv\")\n",
    "pred_df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✅ Saved recommendations: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11ced681-6993-4a63-969c-ea10db499f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Δ: (33388, 20, 1) (33388,)\n",
      "Test  Δ: (8364, 20, 1) (8364,)\n",
      "Epoch 1/12\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - loss: 1.0062 - val_loss: 2.4925\n",
      "Epoch 2/12\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 1.0051 - val_loss: 2.4944\n",
      "Epoch 3/12\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - loss: 1.0047 - val_loss: 2.4872\n",
      "Epoch 4/12\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 1.0047 - val_loss: 2.4872\n",
      "Epoch 5/12\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 1.0045 - val_loss: 2.4811\n",
      "Epoch 6/12\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 1.0045 - val_loss: 2.4830\n",
      "Epoch 7/12\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - loss: 1.0035 - val_loss: 2.4808\n",
      "Epoch 8/12\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - loss: 1.0022 - val_loss: 2.4808\n",
      "Epoch 9/12\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - loss: 1.0004 - val_loss: 2.4823\n",
      "Epoch 10/12\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.9992 - val_loss: 2.4914\n",
      "Epoch 11/12\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - loss: 0.9978 - val_loss: 2.5237\n",
      "Epoch 12/12\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.9946 - val_loss: 2.5206\n",
      "\n",
      "=== Test Metrics on Δ (trained on Δ) ===\n",
      "R² (Δ)   = -0.0060\n",
      "MAE (Δ)  = 0.538976\n",
      "RMSE (Δ) = 1.113275\n",
      "Hit Rate = 0.494\n",
      "\n",
      "=== Reconstructed Close (from Δ) on Test ===\n",
      "R² (Close)   = 0.9987\n",
      "MAE (Close)  = 0.547934\n",
      "RMSE (Close) = 1.244045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample next-day predictions:\n",
      "                                 اسم الشركة  yesterday  predicted_delta  \\\n",
      "0                     البنك السعودي الفرنسي      19.30         0.010686   \n",
      "1                       البنك العربي الوطني      18.97        -0.023904   \n",
      "2  الشركة السعودية لخدمات السيارات والمعدات      63.68        -0.275620   \n",
      "3              الشركة السعودية لصناعة الورق      40.32         0.054115   \n",
      "4          الشركة السعودية للتنمية الصناعية      33.69         0.027845   \n",
      "5         الشركة السعودية للصادرات الصناعية       2.83        -0.000215   \n",
      "6         الشركة السعودية للصناعات المتطورة      28.65         0.022825   \n",
      "7          الشركة السعودية للطباعة والتغليف      15.56         0.002943   \n",
      "8                  الشركة السعودية للكهرباء      18.98         0.009626   \n",
      "9             الشركة السعودية للنقل الجماعي      20.74         0.029127   \n",
      "\n",
      "   predicted_close recommendation  \n",
      "0        19.310686            Buy  \n",
      "1        18.946096      Don’t Buy  \n",
      "2        63.404380      Don’t Buy  \n",
      "3        40.374115            Buy  \n",
      "4        33.717845            Buy  \n",
      "5         2.829785      Don’t Buy  \n",
      "6        28.672825            Buy  \n",
      "7        15.562943            Buy  \n",
      "8        18.989626            Buy  \n",
      "9        20.769127            Buy  \n",
      "✅ Saved model: out\\rnn_on_change.h5\n",
      "✅ Saved next-day predictions: out\\nextday_from_change.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "\n",
    "# =================== إعدادات ===================\n",
    "WIDE_PATH    = \"Equites_Close_Daily.csv\"   # wide: الصف = اسم الشركة، الأعمدة = تواريخ، القيم = إقفال\n",
    "CLEAN_PATH   = \"clean.csv\"                 # long: يحتوي عمود \"التغيير\" اليومي\n",
    "WINDOW_LEN   = 20\n",
    "TRAIN_RATIO  = 0.8\n",
    "EPOCHS       = 12\n",
    "BATCH_SIZE   = 128\n",
    "EPS          = 1e-6\n",
    "\n",
    "# =================== دوال مساعدة ===================\n",
    "def build_sequences(series_vals, window):\n",
    "    X, y = [], []\n",
    "    for t in range(window, len(series_vals)):\n",
    "        feat = series_vals[t-window:t]\n",
    "        target = series_vals[t]\n",
    "        if np.isnan(feat).any() or np.isnan(target):\n",
    "            continue\n",
    "        X.append(feat)\n",
    "        y.append(target)\n",
    "    if not X:\n",
    "        return np.empty((0, window, 1), dtype=\"float32\"), np.empty((0,), dtype=\"float32\")\n",
    "    X = np.array(X, dtype=\"float32\")[:, :, None]\n",
    "    y = np.array(y, dtype=\"float32\")\n",
    "    return X, y\n",
    "\n",
    "def series_from_long(df_long, company_col, date_col, value_col):\n",
    "    \"\"\"حوّل long إلى Series: index=date(str YYYY-MM-DD), values=value (float).\"\"\"\n",
    "    tmp = df_long[[company_col, date_col, value_col]].copy()\n",
    "    tmp[date_col] = pd.to_datetime(tmp[date_col], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
    "    tmp[value_col] = pd.to_numeric(tmp[value_col], errors=\"coerce\")\n",
    "    tmp = tmp.dropna(subset=[date_col, value_col])\n",
    "    return {c: g.drop_duplicates(subset=[date_col]).set_index(date_col)[value_col].sort_index()\n",
    "            for c, g in tmp.groupby(company_col)}\n",
    "\n",
    "# =================== تحميل البيانات ===================\n",
    "# Wide prices (Close)\n",
    "wide = pd.read_csv(WIDE_PATH, encoding=\"utf-8-sig\").set_index(\"اسم الشركة\")\n",
    "wide = wide.apply(pd.to_numeric, errors=\"coerce\")\n",
    "wide.columns = pd.to_datetime(wide.columns, errors=\"coerce\").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Long changes\n",
    "clean = pd.read_csv(CLEAN_PATH, encoding=\"utf-8-sig\")\n",
    "COL_COMPANY = \"اسم الشركة\"\n",
    "COL_DATE    = \"التاريخ\"\n",
    "COL_CHANGE  = \"التغيير\"   # لو أردت النسبة استخدم '% التغيير'\n",
    "\n",
    "change_map = series_from_long(clean, COL_COMPANY, COL_DATE, COL_CHANGE)\n",
    "\n",
    "# سنحتاج أسعار الأمس لإعادة بناء السعر من Δ_pred\n",
    "# نبني أيضاً Series للأسعار لكل شركة (من wide)\n",
    "price_map = {comp: row.dropna().astype(float) for comp, row in wide.iterrows()}\n",
    "\n",
    "# =================== بناء بيانات التدريب على Δ ===================\n",
    "X_tr_list, y_tr_list = [], []\n",
    "X_te_list, y_te_list = [], []\n",
    "te_mu_list, te_sig_list = [], []\n",
    "\n",
    "# للاحتفاظ بمحاذاة الأمس لإعادة بناء السعر، ولحساب Hit Rate على الاختبار\n",
    "prev_close_test_all = []\n",
    "true_close_test_all = []   # لإعادة بناء السعر الحقيقي أيضاً إن أحببنا\n",
    "comp_windows_for_next_pred = []  # لكل شركة: آخر نافذة Δ + سعر الأمس\n",
    "\n",
    "for comp, change_ser in change_map.items():\n",
    "    # التواريخ المشتركة بين تغييرات الشركة وأسعارها (عشان نقدر نرجّع للسعر)\n",
    "    if comp not in price_map:\n",
    "        continue\n",
    "    price_ser = price_map[comp]\n",
    "    common_dates = change_ser.index.intersection(price_ser.index)\n",
    "    if len(common_dates) < WINDOW_LEN + 2:\n",
    "        continue\n",
    "\n",
    "    # مصفوفة Δ مرتبة زمنياً\n",
    "    delta_vals = change_ser.loc[common_dates].values.astype(\"float64\")\n",
    "    # أسعار مطابقة (لنستخدم P_{t-1} لاحقاً)\n",
    "    close_vals = price_ser.loc[common_dates].values.astype(\"float64\")\n",
    "\n",
    "    # بناء تسلسلات على Δ\n",
    "    X_all, y_all = build_sequences(delta_vals, WINDOW_LEN)\n",
    "    if len(y_all) < 3:\n",
    "        continue\n",
    "\n",
    "    # تقسيم\n",
    "    split = max(1, int(len(y_all) * TRAIN_RATIO))\n",
    "    X_tr_c, y_tr_c = X_all[:split], y_all[:split]\n",
    "    X_te_c, y_te_c = X_all[split:], y_all[split:]\n",
    "    if len(y_te_c) == 0:\n",
    "        continue\n",
    "\n",
    "    # تطبيع على Δ (train فقط)\n",
    "    tr_vec = np.concatenate([X_tr_c.reshape(-1), y_tr_c.reshape(-1)])\n",
    "    mu, sig = np.nanmean(tr_vec), np.nanstd(tr_vec)\n",
    "    if not np.isfinite(mu) or sig <= 1e-12:\n",
    "        continue\n",
    "\n",
    "    X_tr_c_n = (X_tr_c - mu) / sig\n",
    "    y_tr_c_n = (y_tr_c - mu) / sig\n",
    "    X_te_c_n = (X_te_c - mu) / sig\n",
    "    y_te_c_n = (y_te_c - mu) / sig\n",
    "\n",
    "    X_tr_list.append(X_tr_c_n); y_tr_list.append(y_tr_c_n)\n",
    "    X_te_list.append(X_te_c_n); y_te_list.append(y_te_c_n)\n",
    "    te_mu_list += [mu] * len(y_te_c_n)\n",
    "    te_sig_list += [sig] * len(y_te_c_n)\n",
    "\n",
    "    # prev_close لكل عينة اختبار = سعر اليوم السابق (أخر عنصر نافذة الأسعار الموافقة)\n",
    "    # نبني prev_close_test_all بمحاذاة عينات الاختبار\n",
    "    # ملاحظة: نافذة Δ بطول WINDOW_LEN تبدأ من t-WINDOW_LEN .. t-1\n",
    "    # بينما prev_close = P_{t-1}\n",
    "    # لنسترجع P_{t-1} نأخذ close_vals مع تعويض نفس عمليات الإسقاط التي قام بها build_sequences\n",
    "    prev_close_all = []\n",
    "    true_close_all = []\n",
    "    for t in range(WINDOW_LEN, len(close_vals)):\n",
    "        if t < split + WINDOW_LEN:  # هذه عينات train\n",
    "            continue\n",
    "        prev_close_all.append(close_vals[t-1])\n",
    "        true_close_all.append(close_vals[t])\n",
    "    prev_close_test_all.extend(prev_close_all)\n",
    "    true_close_test_all.extend(true_close_all)\n",
    "\n",
    "    # تحضير تنبؤ اليوم التالي لكل شركة (آخر نافذة Δ)\n",
    "    last_delta_window = delta_vals[-WINDOW_LEN:]\n",
    "    if not np.isnan(last_delta_window).any():\n",
    "        comp_windows_for_next_pred.append({\n",
    "            \"اسم الشركة\": comp,\n",
    "            \"last_window_norm\": ((last_delta_window - mu) / sig).astype(\"float32\").reshape(1, WINDOW_LEN, 1),\n",
    "            \"mu\": mu, \"sig\": sig,\n",
    "            \"yesterday_close\": close_vals[-1]\n",
    "        })\n",
    "\n",
    "# دمج\n",
    "X_train = np.concatenate(X_tr_list, axis=0) if X_tr_list else np.empty((0, WINDOW_LEN, 1), dtype=\"float32\")\n",
    "y_train = np.concatenate(y_tr_list, axis=0) if y_tr_list else np.empty((0,), dtype=\"float32\")\n",
    "X_test  = np.concatenate(X_te_list, axis=0) if X_te_list else np.empty((0, WINDOW_LEN, 1), dtype=\"float32\")\n",
    "y_test  = np.concatenate(y_te_list, axis=0) if y_te_list else np.empty((0,), dtype=\"float32\")\n",
    "te_mu   = np.array(te_mu_list, dtype=\"float64\")\n",
    "te_sig  = np.array(te_sig_list, dtype=\"float64\")\n",
    "prev_close_test_all = np.array(prev_close_test_all, dtype=\"float64\")\n",
    "true_close_test_all = np.array(true_close_test_all, dtype=\"float64\")\n",
    "\n",
    "print(\"Train Δ:\", X_train.shape, y_train.shape)\n",
    "print(\"Test  Δ:\", X_test.shape,  y_test.shape)\n",
    "\n",
    "# =================== نموذج RNN على Δ ===================\n",
    "tf.keras.backend.clear_session()\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(WINDOW_LEN, 1)),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.LSTM(32),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# =================== تقييم على Δ ===================\n",
    "y_hat_n = model.predict(X_test, verbose=0).reshape(-1)\n",
    "y_pred_delta = y_hat_n * te_sig + te_mu     # التغير المتنبأ\n",
    "y_true_delta = y_test   * te_sig + te_mu     # التغير الحقيقي\n",
    "\n",
    "R2_delta   = r2_score(y_true_delta, y_pred_delta)\n",
    "MAE_delta  = mean_absolute_error(y_true_delta, y_pred_delta)\n",
    "RMSE_delta = float(np.sqrt(mean_squared_error(y_true_delta, y_pred_delta)))\n",
    "\n",
    "# اتجاه الحركة (Hit Rate)\n",
    "hit_rate = np.mean(np.sign(y_true_delta) == np.sign(y_pred_delta)) if y_true_delta.size else np.nan\n",
    "\n",
    "print(\"\\n=== Test Metrics on Δ (trained on Δ) ===\")\n",
    "print(f\"R² (Δ)   = {R2_delta:.4f}\")\n",
    "print(f\"MAE (Δ)  = {MAE_delta:.6f}\")\n",
    "print(f\"RMSE (Δ) = {RMSE_delta:.6f}\")\n",
    "print(f\"Hit Rate = {hit_rate:.3f}\")\n",
    "\n",
    "# (اختياري) نسب التغير الآمنة\n",
    "valid_pct = np.abs(prev_close_test_all) > EPS\n",
    "if valid_pct.sum() == y_true_delta.size == y_pred_delta.size:\n",
    "    true_pct = y_true_delta[valid_pct] / prev_close_test_all[valid_pct]\n",
    "    pred_pct = y_pred_delta[valid_pct] / prev_close_test_all[valid_pct]\n",
    "    if true_pct.size > 0:\n",
    "        R2_pct   = r2_score(true_pct, pred_pct)\n",
    "        MAE_pct  = mean_absolute_error(true_pct, pred_pct)\n",
    "        RMSE_pct = float(np.sqrt(mean_squared_error(true_pct, pred_pct)))\n",
    "        smape    = np.mean(2.0*np.abs(pred_pct-true_pct)/(np.abs(pred_pct)+np.abs(true_pct)+EPS))\n",
    "        print(\"\\n=== Δ% Metrics (filtered) ===\")\n",
    "        print(f\"R² (Δ%)   = {R2_pct:.4f}\")\n",
    "        print(f\"MAE (Δ%)  = {MAE_pct:.6f}\")\n",
    "        print(f\"RMSE (Δ%) = {RMSE_pct:.6f}\")\n",
    "        print(f\"sMAPE     = {smape:.6f}\")\n",
    "\n",
    "# =================== إعادة بناء السعر + توصيات ===================\n",
    "# السعر المتنبأ لعَيّنات الاختبار (للمراجعة): P_hat = P_{t-1} + Δ_hat\n",
    "if prev_close_test_all.size == y_pred_delta.size:\n",
    "    price_pred_test = prev_close_test_all + y_pred_delta\n",
    "    price_true_test = true_close_test_all\n",
    "    R2_price   = r2_score(price_true_test, price_pred_test)\n",
    "    MAE_price  = mean_absolute_error(price_true_test, price_pred_test)\n",
    "    RMSE_price = float(np.sqrt(mean_squared_error(price_true_test, price_pred_test)))\n",
    "    print(\"\\n=== Reconstructed Close (from Δ) on Test ===\")\n",
    "    print(f\"R² (Close)   = {R2_price:.4f}\")\n",
    "    print(f\"MAE (Close)  = {MAE_price:.6f}\")\n",
    "    print(f\"RMSE (Close) = {RMSE_price:.6f}\")\n",
    "\n",
    "# توقع اليوم التالي لكل شركة\n",
    "pred_rows = []\n",
    "for rec in comp_windows_for_next_pred:\n",
    "    comp = rec[\"اسم الشركة\"]\n",
    "    yhat_n = model.predict(rec[\"last_window_norm\"], verbose=0).reshape(-1)[0]\n",
    "    delta_pred = yhat_n * rec[\"sig\"] + rec[\"mu\"]     # Δ_pred للغد\n",
    "    yesterday  = rec[\"yesterday_close\"]\n",
    "    tomorrow_pred_price = float(yesterday + delta_pred)\n",
    "    recommendation = \"Buy\" if delta_pred > 0 else \"Don’t Buy\"\n",
    "    pred_rows.append({\n",
    "        \"اسم الشركة\": comp,\n",
    "        \"yesterday\": float(yesterday),\n",
    "        \"predicted_delta\": float(delta_pred),\n",
    "        \"predicted_close\": tomorrow_pred_price,\n",
    "        \"recommendation\": recommendation\n",
    "    })\n",
    "\n",
    "pred_df = pd.DataFrame(pred_rows).sort_values(\"اسم الشركة\")\n",
    "print(\"\\nSample next-day predictions:\")\n",
    "print(pred_df.head(10))\n",
    "\n",
    "# =================== الحفظ ===================\n",
    "OUT_DIR = \"out\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(OUT_DIR, \"rnn_on_change.h5\")\n",
    "model.save(model_path)\n",
    "print(f\"✅ Saved model: {model_path}\")\n",
    "\n",
    "csv_path = os.path.join(OUT_DIR, \"nextday_from_change.csv\")\n",
    "pred_df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✅ Saved next-day predictions: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46eed1a-ec85-4c9e-9e82-ed95424f501c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
