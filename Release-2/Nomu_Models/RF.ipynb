{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd91ab7f-6c13-4aeb-8926-06c514a1c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json, joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Pretty numbers in notebook (no scientific notation)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.4f}')\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Paths\n",
    "DATA_CSV = \"clean.csv\"\n",
    "OUT_DIR = Path(\"out\"); OUT_DIR.mkdir(exist_ok=True)\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7144c3b3-028b-439c-9af7-4c7f063c5b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249300, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>القطاع</th>\n",
       "      <th>رمز الشركة</th>\n",
       "      <th>اسم الشركة</th>\n",
       "      <th>التاريخ</th>\n",
       "      <th>إفتتاح</th>\n",
       "      <th>الأعلى</th>\n",
       "      <th>الأدنى</th>\n",
       "      <th>إقفال</th>\n",
       "      <th>التغيير</th>\n",
       "      <th>% التغيير</th>\n",
       "      <th>الكمية المتداولة</th>\n",
       "      <th>اجمالي القيمة المتداولة (ر.س)</th>\n",
       "      <th>عدد الصفقات</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>البنوك</td>\n",
       "      <td>1010</td>\n",
       "      <td>بنك الرياض</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>27.8500</td>\n",
       "      <td>28.1000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>3544508</td>\n",
       "      <td>99,916,754.1500</td>\n",
       "      <td>3302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>البنوك</td>\n",
       "      <td>1010</td>\n",
       "      <td>بنك الرياض</td>\n",
       "      <td>2025-05-29</td>\n",
       "      <td>28.2500</td>\n",
       "      <td>29.0500</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>29.0500</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>3.3800</td>\n",
       "      <td>6007732</td>\n",
       "      <td>172,610,047.4000</td>\n",
       "      <td>3181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>البنوك</td>\n",
       "      <td>1010</td>\n",
       "      <td>بنك الرياض</td>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>28.0500</td>\n",
       "      <td>27.5500</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1928922</td>\n",
       "      <td>53,653,332.8500</td>\n",
       "      <td>2106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>البنوك</td>\n",
       "      <td>1010</td>\n",
       "      <td>بنك الرياض</td>\n",
       "      <td>2025-05-25</td>\n",
       "      <td>28.3500</td>\n",
       "      <td>28.3500</td>\n",
       "      <td>28.1000</td>\n",
       "      <td>28.2500</td>\n",
       "      <td>-0.1000</td>\n",
       "      <td>-0.3500</td>\n",
       "      <td>529542</td>\n",
       "      <td>14,941,194.8000</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>البنوك</td>\n",
       "      <td>1010</td>\n",
       "      <td>بنك الرياض</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>28.6500</td>\n",
       "      <td>28.6500</td>\n",
       "      <td>27.8000</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>-0.8800</td>\n",
       "      <td>1763003</td>\n",
       "      <td>49,366,287.0000</td>\n",
       "      <td>2445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   القطاع  رمز الشركة  اسم الشركة    التاريخ  إفتتاح  الأعلى  الأدنى   إقفال  \\\n",
       "0  البنوك        1010  بنك الرياض 2025-05-28 28.0000 28.5000 27.8500 28.1000   \n",
       "1  البنوك        1010  بنك الرياض 2025-05-29 28.2500 29.0500 28.0000 29.0500   \n",
       "2  البنوك        1010  بنك الرياض 2025-05-27 28.0000 28.0500 27.5500 28.0000   \n",
       "3  البنوك        1010  بنك الرياض 2025-05-25 28.3500 28.3500 28.1000 28.2500   \n",
       "4  البنوك        1010  بنك الرياض 2025-05-26 28.6500 28.6500 27.8000 28.0000   \n",
       "\n",
       "   التغيير  % التغيير  الكمية المتداولة  اجمالي القيمة المتداولة (ر.س)  \\\n",
       "0   0.1000     0.3600           3544508                99,916,754.1500   \n",
       "1   0.9500     3.3800           6007732               172,610,047.4000   \n",
       "2   0.0000     0.0000           1928922                53,653,332.8500   \n",
       "3  -0.1000    -0.3500            529542                14,941,194.8000   \n",
       "4  -0.2500    -0.8800           1763003                49,366,287.0000   \n",
       "\n",
       "   عدد الصفقات  \n",
       "0         3302  \n",
       "1         3181  \n",
       "2         2106  \n",
       "3          808  \n",
       "4         2445  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load\n",
    "df = pd.read_csv(DATA_CSV, encoding=\"utf-8-sig\")\n",
    "\n",
    "# Expected Arabic columns (from your screenshot)\n",
    "COL_SECTOR   = \"القطاع\"\n",
    "COL_SYMBOL   = \"رمز الشركة\"\n",
    "COL_NAME     = \"اسم الشركة\"\n",
    "COL_DATE     = \"التاريخ\"\n",
    "COL_OPEN     = \"إفتتاح\"\n",
    "COL_HIGH     = \"الأعلى\"\n",
    "COL_LOW      = \"الأدنى\"\n",
    "COL_CLOSE    = \"إقفال\"\n",
    "COL_CHANGE   = \"التغيير\"\n",
    "COL_PCT      = \"% التغيير\"\n",
    "COL_VOLUME   = \"الكمية المتداولة\"\n",
    "COL_TURNOVER = \"اجمالي القيمة المتداولة (ر.س)\"\n",
    "COL_TRADES   = \"عدد الصفقات\"\n",
    "\n",
    "# Parse date\n",
    "df[COL_DATE] = pd.to_datetime(df[COL_DATE], errors=\"coerce\")\n",
    "\n",
    "# Ensure numeric for features\n",
    "num_cols = [COL_OPEN, COL_HIGH, COL_LOW, COL_CLOSE, COL_CHANGE, COL_PCT,\n",
    "            COL_VOLUME, COL_TURNOVER, COL_TRADES]\n",
    "for c in num_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Drop rows with missing key fields\n",
    "df = df.dropna(subset=[COL_DATE, COL_SYMBOL, COL_CLOSE]).copy()\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37ff91db-645b-4dc4-960b-a449f56638f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      رمز الشركة    التاريخ   إقفال  next_close  % التغيير  next_pct  \\\n",
      "2369        1010 2015-08-25 14.9900     14.8100     8.0700   -1.2000   \n",
      "2370        1010 2015-08-26 14.8100     14.8500    -1.2000    0.2700   \n",
      "2371        1010 2015-08-27 14.8500     14.8700     0.2700    0.1300   \n",
      "2372        1010 2015-08-30 14.8700     14.5400     0.1300   -2.2200   \n",
      "2373        1010 2015-08-31 14.5400     14.5800    -2.2200    0.2800   \n",
      "2374        1010 2015-09-01 14.5800     14.4000     0.2800   -1.2300   \n",
      "2375        1010 2015-09-02 14.4000     14.4300    -1.2300    0.2100   \n",
      "2376        1010 2015-09-03 14.4300     14.4400     0.2100    0.0700   \n",
      "2377        1010 2015-09-06 14.4400     14.3400     0.0700   -0.6900   \n",
      "2378        1010 2015-09-07 14.3400     14.5000    -0.6900    1.1200   \n",
      "\n",
      "      target_change_next  target_close_next  \n",
      "2369                   0                  0  \n",
      "2370                   1                  1  \n",
      "2371                   1                  1  \n",
      "2372                   0                  0  \n",
      "2373                   1                  1  \n",
      "2374                   0                  0  \n",
      "2375                   1                  1  \n",
      "2376                   1                  1  \n",
      "2377                   0                  0  \n",
      "2378                   1                  1  \n"
     ]
    }
   ],
   "source": [
    "# ---- NEXT-DAY targets (no label leakage) ----\n",
    "df = df.sort_values([COL_SYMBOL, COL_DATE]).copy()\n",
    "\n",
    "# Next day's close & % change per symbol\n",
    "df[\"next_close\"] = df.groupby(COL_SYMBOL)[COL_CLOSE].shift(-1)\n",
    "df[\"next_pct\"]   = df.groupby(COL_SYMBOL)[COL_PCT].shift(-1)\n",
    "\n",
    "# A) change-based NEXT DAY: BUY if next day's % change > 0\n",
    "df[\"target_change_next\"] = (df[\"next_pct\"] > 0).astype(float)\n",
    "\n",
    "# B) close-based NEXT DAY: BUY if next day's close > today's close\n",
    "df[\"target_close_next\"]  = (df[\"next_close\"] > df[COL_CLOSE]).astype(float)\n",
    "\n",
    "# drop rows where next day doesn't exist (last row per symbol)\n",
    "df = df.dropna(subset=[\"target_change_next\", \"target_close_next\"]).copy()\n",
    "df[\"target_change_next\"] = df[\"target_change_next\"].astype(int)\n",
    "df[\"target_close_next\"]  = df[\"target_close_next\"].astype(int)\n",
    "\n",
    "print(\n",
    "    df[[COL_SYMBOL, COL_DATE, COL_CLOSE, \"next_close\", COL_PCT, \"next_pct\",\n",
    "        \"target_change_next\",\"target_close_next\"]].head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20353c63-bf62-4d3a-b4ce-d11d1a1b9b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features (NO trades): ['إفتتاح', 'الأعلى', 'الأدنى', 'إقفال', 'التغيير', '% التغيير', 'الكمية المتداولة', 'اجمالي القيمة المتداولة (ر.س)']\n"
     ]
    }
   ],
   "source": [
    "# ========= Cell 4 (REPLACE THIS CELL) =========\n",
    "# Feature set WITHOUT 'عدد الصفقات (trades)'\n",
    "FEATURES = [\n",
    "    COL_OPEN, COL_HIGH, COL_LOW, COL_CLOSE, COL_CHANGE, COL_PCT,\n",
    "    COL_VOLUME, COL_TURNOVER\n",
    "]\n",
    "FEATURES = [c for c in FEATURES if c in df.columns]  # keep only existing\n",
    "\n",
    "print(\"Using features (NO trades):\", FEATURES)\n",
    "\n",
    "def train_and_eval_model(X, y, name, out_prefix):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "    import joblib, json\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    rep = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    # NOTE: new filenames so we don't confuse with the old (with-trades) models\n",
    "    model_path = OUT_DIR / f\"{out_prefix}_model_notrades.joblib\"\n",
    "    joblib.dump(clf, model_path)\n",
    "    with open(OUT_DIR / f\"{out_prefix}_metrics_notrades.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"accuracy\": acc, \"report\": rep}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"{name} accuracy (NO trades): {acc:.4f}\")\n",
    "    return clf, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca5e31c8-ebad-474b-87c8-3f1a258c6b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change-based (next-day, NO trades) accuracy: 0.5217\n",
      "Close-based (next-day, NO trades) accuracy: 0.5263\n",
      "\n",
      "✅ Best model (NO trades): close_notrades (accuracy=0.5263)\n"
     ]
    }
   ],
   "source": [
    "# ========= Cell 5 (REPLACE THIS CELL — time-based split, NO trades) =========\n",
    "\n",
    "# Time-based split: last 20% (by date) per symbol = test\n",
    "def time_split_per_symbol(frame, test_frac=0.20):\n",
    "    parts = []\n",
    "    for sym, g in frame.sort_values(COL_DATE).groupby(COL_SYMBOL):\n",
    "        n = len(g)\n",
    "        k = max(1, int(n * (1 - test_frac)))\n",
    "        g = g.copy()\n",
    "        g[\"is_test\"] = False\n",
    "        g.iloc[k:, g.columns.get_loc(\"is_test\")] = True\n",
    "        parts.append(g)\n",
    "    return pd.concat(parts, ignore_index=True)\n",
    "\n",
    "# Prepare two datasets sharing same FEATURES (NO trades)\n",
    "use_cols = FEATURES + [\"target_change_next\",\"target_close_next\", COL_SYMBOL, COL_DATE]\n",
    "work = df.dropna(subset=FEATURES).copy()[use_cols]\n",
    "\n",
    "# Split\n",
    "split = time_split_per_symbol(work, test_frac=0.20)\n",
    "\n",
    "def train_eval_time(df_split, y_col, name, out_prefix):\n",
    "    train = df_split[df_split[\"is_test\"] == False]\n",
    "    test  = df_split[df_split[\"is_test\"] == True]\n",
    "\n",
    "    X_train = train[FEATURES].astype(np.float64).values\n",
    "    y_train = train[y_col].values\n",
    "    X_test  = test[FEATURES].astype(np.float64).values\n",
    "    y_test  = test[y_col].values\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    rep = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    # Save model + metrics with _notrades suffix\n",
    "    model_path = OUT_DIR / f\"{out_prefix}_model_notrades.joblib\"\n",
    "    joblib.dump(clf, model_path)\n",
    "    with open(OUT_DIR / f\"{out_prefix}_metrics_notrades.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"accuracy\": float(acc), \"report\": rep}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"{name} (next-day, NO trades) accuracy: {acc:.4f}\")\n",
    "    return clf, acc\n",
    "\n",
    "# A) change-based (next day)\n",
    "clf_change, acc_change = train_eval_time(split, \"target_change_next\", \"Change-based\", \"change\")\n",
    "\n",
    "# B) close-based (next day)\n",
    "clf_close, acc_close   = train_eval_time(split, \"target_close_next\",  \"Close-based\",  \"close\")\n",
    "\n",
    "# Pick better\n",
    "if acc_close >= acc_change:\n",
    "    best_name = \"close_notrades\"\n",
    "    best_clf  = clf_close\n",
    "    best_acc  = acc_close\n",
    "    best_target = \"target_close_next\"\n",
    "else:\n",
    "    best_name = \"change_notrades\"\n",
    "    best_clf  = clf_change\n",
    "    best_acc  = acc_change\n",
    "    best_target = \"target_change_next\"\n",
    "\n",
    "print(f\"\\n✅ Best model (NO trades): {best_name} (accuracy={best_acc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3028b7f-ec99-4e5e-a04c-5ff8d940a13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asma5\\AppData\\Local\\Temp\\ipykernel_22268\\1418640574.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  scored_all[\"decision\"].fillna(\"لا تشتري\", inplace=True)\n",
      "C:\\Users\\asma5\\AppData\\Local\\Temp\\ipykernel_22268\\1418640574.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  scored_all[\"proba_buy\"].fillna(0.0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ wrote: out\\predictions_all_dates_next.csv\n",
      "rows in clean (with features): 249300\n",
      "rows in predictions file     : 249300\n",
      "rows with اشتري but proba<0.5: 0\n"
     ]
    }
   ],
   "source": [
    "# ===================== Cell 6 — SCORE & KEEP ALL ROWS =====================\n",
    "\n",
    "# 1) sort & keep rows that have all features\n",
    "scored_all = df.sort_values([COL_SYMBOL, COL_DATE]).copy()\n",
    "scored_all = scored_all.dropna(subset=FEATURES).copy()\n",
    "\n",
    "# 2) model probabilities (always pick the column for class==1 i.e., BUY)\n",
    "X_all = scored_all[FEATURES].astype(np.float64).values\n",
    "proba_all = best_clf.predict_proba(X_all)\n",
    "buy_col = np.where(best_clf.classes_ == 1)[0][0]\n",
    "scored_all[\"proba_buy\"] = proba_all[:, buy_col]\n",
    "scored_all[\"decision\"]  = np.where(scored_all[\"proba_buy\"] >= 0.5, \"اشتري\", \"لا تشتري\")\n",
    "\n",
    "# 3) align each row's prediction to the NEXT day (T -> T+1)\n",
    "scored_all[\"pred_date\"] = scored_all.groupby(COL_SYMBOL)[COL_DATE].shift(-1)\n",
    "\n",
    "# 4) for the LAST day per symbol (no T+1): keep the row and INHERIT previous class\n",
    "mask_last = scored_all[\"pred_date\"].isna()\n",
    "\n",
    "# pred_date becomes the same day's date (so we still output something for that date)\n",
    "scored_all.loc[mask_last, \"pred_date\"] = scored_all.loc[mask_last, COL_DATE]\n",
    "\n",
    "# inherit yesterday's predicted decision/proba (the signal meant for \"today\")\n",
    "prev_decision = scored_all.groupby(COL_SYMBOL)[\"decision\"].shift(1)\n",
    "prev_proba    = scored_all.groupby(COL_SYMBOL)[\"proba_buy\"].shift(1)\n",
    "scored_all.loc[mask_last, \"decision\"]  = prev_decision[mask_last]\n",
    "scored_all.loc[mask_last, \"proba_buy\"] = prev_proba[mask_last]\n",
    "\n",
    "# if the very first row of a symbol had no previous signal, fill a safe default\n",
    "scored_all[\"decision\"].fillna(\"لا تشتري\", inplace=True)\n",
    "scored_all[\"proba_buy\"].fillna(0.0, inplace=True)\n",
    "\n",
    "# (optional) keep the feature day for clarity\n",
    "scored_all[\"today_date\"] = scored_all[COL_DATE]\n",
    "\n",
    "# 5) export: one row per (symbol, date) where \"date\" is the day the decision applies to\n",
    "export_cols = [COL_SYMBOL, COL_NAME, \"today_date\", \"pred_date\", COL_CLOSE, COL_PCT, \"proba_buy\", \"decision\"]\n",
    "scored_all_out = scored_all[export_cols].rename(columns={\n",
    "    COL_SYMBOL: \"symbol\",\n",
    "    COL_NAME:   \"company\",\n",
    "    \"pred_date\":\"date\",      # the day the decision applies to\n",
    "    COL_CLOSE:  \"close\",\n",
    "    COL_PCT:    \"pct_change\"\n",
    "})\n",
    "\n",
    "out_path = OUT_DIR / \"predictions_all_dates_next.csv\"\n",
    "scored_all_out.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ wrote:\", out_path)\n",
    "\n",
    "# sanity: lengths should match (no rows dropped because of last day)\n",
    "print(\"rows in clean (with features):\", len(df.dropna(subset=FEATURES)))\n",
    "print(\"rows in predictions file     :\", len(scored_all_out))\n",
    "\n",
    "# sanity: no 'اشتري' with proba<0.5 (after inheritance)\n",
    "bad = (scored_all_out[\"decision\"] == \"اشتري\") & (scored_all_out[\"proba_buy\"] < 0.5)\n",
    "print(\"rows with اشتري but proba<0.5:\", int(bad.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe0ba8a9-de53-4981-a8a9-6a8ee3d363e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded model: out\\close_model_notrades.joblib\n",
      "Companies found: 20\n",
      "Pulled rows: 24960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asma5\\AppData\\Local\\Temp\\ipykernel_22268\\3213217291.py:138: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"decision\"].fillna(\"لا تشتري\", inplace=True)\n",
      "C:\\Users\\asma5\\AppData\\Local\\Temp\\ipykernel_22268\\3213217291.py:139: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"proba_buy\"].fillna(0.0, inplace=True)\n",
      "C:\\Users\\asma5\\AppData\\Local\\Temp\\ipykernel_22268\\3213217291.py:165: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now_iso = dt.datetime.utcnow().isoformat() + \"Z\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote 24960 docs to 'market_predictions_daily' (one per symbol+date).\n"
     ]
    }
   ],
   "source": [
    "# ===================== Cell 7 — Batch score Firestore (NO trades) =====================\n",
    "# Reads ALL days in companies/*/PriceRecords_full, predicts T->T+1, keeps last day, writes to market_predictions_daily\n",
    "\n",
    "import pandas as pd, numpy as np, datetime as dt, re\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore\n",
    "\n",
    "# --- CONFIG (edit paths if needed) ---\n",
    "SERVICE_ACCOUNT_JSON = r\"nomu-47a92-firebase-adminsdk-fbsvc-1b2e28026c.json\"       # <-- change me\n",
    "MODEL_PATH           = Path(\"out/close_model_notrades.joblib\")    # or out/change_model_notrades.joblib\n",
    "COMPANIES_COLLECTION = \"companies\"\n",
    "PRICE_SUBCOLLECTION  = \"PriceRecords_full\"\n",
    "TARGET_DAILY_COL     = \"market_predictions_daily\"\n",
    "\n",
    "# Arabic labels used in your training notebook\n",
    "COL_SYMBOL   = \"رمز الشركة\"\n",
    "COL_NAME     = \"اسم الشركة\"\n",
    "COL_DATE     = \"التاريخ\"\n",
    "COL_OPEN     = \"إفتتاح\"\n",
    "COL_HIGH     = \"الأعلى\"\n",
    "COL_LOW      = \"الأدنى\"\n",
    "COL_CLOSE    = \"إقفال\"\n",
    "COL_CHANGE   = \"التغيير\"\n",
    "COL_PCT      = \"% التغيير\"\n",
    "COL_VOLUME   = \"الكمية المتداولة\"\n",
    "COL_TURNOVER = \"اجمالي القيمة المتداولة (ر.س)\"\n",
    "\n",
    "# 8 features (NO trades)\n",
    "FEATURES = [COL_OPEN, COL_HIGH, COL_LOW, COL_CLOSE, COL_CHANGE, COL_PCT, COL_VOLUME, COL_TURNOVER]\n",
    "\n",
    "# Map Firestore field names -> your model column names\n",
    "FS_TO_MODEL = {\n",
    "    \"open\":        COL_OPEN,\n",
    "    \"high\":        COL_HIGH,\n",
    "    \"low\":         COL_LOW,\n",
    "    \"close\":       COL_CLOSE,\n",
    "    \"change\":      COL_CHANGE,\n",
    "    \"change_pct\":  COL_PCT,\n",
    "    \"volume\":      COL_VOLUME,\n",
    "    \"value\":       COL_TURNOVER,   # Firestore uses 'value' for turnover\n",
    "    \"date\":        COL_DATE,\n",
    "}\n",
    "\n",
    "def norm_key(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = s.replace(\"إ\",\"ا\").replace(\"أ\",\"ا\").replace(\"آ\",\"ا\").replace(\"ٱ\",\"ا\").replace(\"ى\",\"ي\").replace(\"ة\",\"ه\")\n",
    "    return re.sub(r\"\\s+\", \"\", s).lower()\n",
    "\n",
    "def pick(d: dict, *cands, default=None):\n",
    "    \"\"\"Pick first existing key among candidates (arabic/normalized).\"\"\"\n",
    "    if not d: return default\n",
    "    # direct\n",
    "    for k in cands:\n",
    "        if k in d and d[k] is not None:\n",
    "            return d[k]\n",
    "    # normalized\n",
    "    nd = {norm_key(k): v for k, v in d.items()}\n",
    "    for k in cands:\n",
    "        nk = norm_key(k)\n",
    "        if nk in nd and nd[nk] is not None:\n",
    "            return nd[nk]\n",
    "    return default\n",
    "\n",
    "# --- Firestore init + model load ---\n",
    "if not firebase_admin._apps:\n",
    "    cred = credentials.Certificate(SERVICE_ACCOUNT_JSON)\n",
    "    firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n",
    "clf = joblib.load(MODEL_PATH)\n",
    "print(\"✅ Loaded model:\", MODEL_PATH)\n",
    "\n",
    "# --- Pull ALL companies and ALL their daily records ---\n",
    "rows = []\n",
    "companies = list(db.collection(COMPANIES_COLLECTION).stream())\n",
    "print(\"Companies found:\", len(companies))\n",
    "\n",
    "for comp in companies:\n",
    "    c = comp.to_dict() or {}\n",
    "    symbol = str(pick(c, \"id\", \"symbol\", COL_SYMBOL, default=comp.id)).strip()\n",
    "    name   = pick(c, \"name\", COL_NAME, default=comp.id)\n",
    "\n",
    "    price_ref = db.collection(COMPANIES_COLLECTION).document(comp.id).collection(PRICE_SUBCOLLECTION)\n",
    "    for rec in price_ref.stream():  # streams ALL docs in that subcollection\n",
    "        d = rec.to_dict() or {}\n",
    "        row = {\"symbol\": symbol, \"company\": name}\n",
    "        for fs_key, model_key in FS_TO_MODEL.items():\n",
    "            row[model_key] = pick(d, fs_key, model_key)\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "if df.empty:\n",
    "    raise RuntimeError(\"No data found under companies/*/PriceRecords_full\")\n",
    "print(\"Pulled rows:\", len(df))\n",
    "\n",
    "# --- Types & cleaning ---\n",
    "df[COL_DATE] = pd.to_datetime(df[COL_DATE], errors=\"coerce\")\n",
    "for c in FEATURES:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Keep essential rows\n",
    "df = df.dropna(subset=[COL_DATE, COL_CLOSE]).copy()\n",
    "df[\"symbol\"] = df[\"symbol\"].astype(str).str.strip()\n",
    "\n",
    "# If any feature column is entirely missing, create it with safe default\n",
    "fill_defaults = {\n",
    "    COL_OPEN: np.nan, COL_HIGH: np.nan, COL_LOW: np.nan, COL_CLOSE: np.nan,\n",
    "    COL_CHANGE: 0.0, COL_PCT: 0.0, COL_VOLUME: 0.0, COL_TURNOVER: 0.0\n",
    "}\n",
    "for f in FEATURES:\n",
    "    if f not in df.columns:\n",
    "        df[f] = fill_defaults.get(f, 0.0)\n",
    "\n",
    "# --- Predict BUY probability for ALL DAYS ---\n",
    "df = df.sort_values([\"symbol\", COL_DATE]).copy()\n",
    "\n",
    "# build a per-column defaults dict, then fill and cast\n",
    "fill_map = {c: fill_defaults.get(c, 0.0) for c in FEATURES}\n",
    "X_df = df[FEATURES].fillna(fill_map).astype(np.float64)\n",
    "\n",
    "X = X_df.values\n",
    "proba = clf.predict_proba(X)\n",
    "buy_col = np.where(clf.classes_ == 1)[0][0]    # robustly choose BUY column\n",
    "df[\"proba_buy\"] = proba[:, buy_col]\n",
    "df[\"decision\"]  = np.where(df[\"proba_buy\"] >= 0.5, \"اشتري\", \"لا تشتري\")\n",
    "\n",
    "# --- Align prediction to NEXT day and KEEP last day via inheritance ---\n",
    "df[\"pred_date\"] = df.groupby(\"symbol\")[COL_DATE].shift(-1)\n",
    "\n",
    "mask_last = df[\"pred_date\"].isna()\n",
    "df.loc[mask_last, \"pred_date\"] = df.loc[mask_last, COL_DATE]          # keep last day\n",
    "df[\"decision\"]  = df.groupby(\"symbol\")[\"decision\"].ffill()\n",
    "df[\"proba_buy\"] = df.groupby(\"symbol\")[\"proba_buy\"].ffill()\n",
    "df[\"decision\"].fillna(\"لا تشتري\", inplace=True)\n",
    "df[\"proba_buy\"].fillna(0.0, inplace=True)\n",
    "\n",
    "# --- Prepare rows to write (with company, change, pct_change, classification, OHLC) ---\n",
    "to_write = df[\n",
    "    [\n",
    "        \"symbol\", \"company\", \"pred_date\",\n",
    "        COL_OPEN, COL_HIGH, COL_LOW, COL_CLOSE,\n",
    "        COL_CHANGE, COL_PCT,\n",
    "        \"proba_buy\", \"decision\"\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "to_write = to_write.rename(columns={\n",
    "    \"pred_date\": \"date\",\n",
    "    COL_OPEN: \"open\",\n",
    "    COL_HIGH: \"high\",\n",
    "    COL_LOW:  \"low\",\n",
    "    COL_CLOSE:\"close\",\n",
    "    COL_CHANGE:\"change\",\n",
    "    COL_PCT:  \"pct_change\",\n",
    "})\n",
    "\n",
    "# --- Write to Firestore: market_predictions_daily/{symbol_YYYY-MM-DD} ---\n",
    "def make_doc_id(symbol, date_str):\n",
    "    return f\"{symbol}_{pd.to_datetime(date_str).date().isoformat()}\"\n",
    "\n",
    "now_iso = dt.datetime.utcnow().isoformat() + \"Z\"\n",
    "batch = db.batch()\n",
    "BATCH_LIMIT = 500\n",
    "ops = 0\n",
    "written = 0\n",
    "\n",
    "for _, r in to_write.iterrows():\n",
    "    sid = str(r[\"symbol\"]).strip()\n",
    "    d   = pd.to_datetime(r[\"date\"]).date().isoformat()\n",
    "    ref = db.collection(TARGET_DAILY_COL).document(make_doc_id(sid, d))\n",
    "\n",
    "    payload = {\n",
    "        \"symbol\": sid,\n",
    "        \"company\": r[\"company\"],\n",
    "        \"date\": d,  # YYYY-MM-DD\n",
    "        \"open\":  float(r[\"open\"])  if pd.notnull(r[\"open\"])  else None,\n",
    "        \"high\":  float(r[\"high\"])  if pd.notnull(r[\"high\"])  else None,\n",
    "        \"low\":   float(r[\"low\"])   if pd.notnull(r[\"low\"])   else None,\n",
    "        \"close\": float(r[\"close\"]) if pd.notnull(r[\"close\"]) else None,\n",
    "\n",
    "        \"change\":     float(r[\"change\"])     if pd.notnull(r[\"change\"])     else None,\n",
    "        \"pct_change\": float(r[\"pct_change\"]) if pd.notnull(r[\"pct_change\"]) else None,\n",
    "\n",
    "        \"proba_buy\": float(r[\"proba_buy\"]) if pd.notnull(r[\"proba_buy\"]) else None,\n",
    "        \"decision\": r[\"decision\"],\n",
    "\n",
    "        \"updatedAt\": now_iso,\n",
    "    }\n",
    "\n",
    "    batch.set(ref, payload, merge=True)\n",
    "    ops += 1; written += 1\n",
    "\n",
    "    if ops >= BATCH_LIMIT:\n",
    "        batch.commit()\n",
    "        batch = db.batch()\n",
    "        ops = 0\n",
    "\n",
    "if ops:\n",
    "    batch.commit()\n",
    "\n",
    "print(f\"✅ Wrote {written} docs to '{TARGET_DAILY_COL}' (one per symbol+date).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da5ef29f-32ae-48eb-aed9-4a272a699e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows pulled from Firestore: 24960\n",
      "Unique symbols: 20\n",
      "Sample per-symbol date stats:\n",
      "  symbol        min        max  nunique\n",
      "0   1140 2019-01-01 2023-12-31     1248\n",
      "1   1212 2019-01-01 2023-12-31     1248\n",
      "2   1810 2019-01-01 2023-12-31     1248\n",
      "3   2010 2019-01-01 2023-12-31     1248\n",
      "4   2070 2019-01-01 2023-12-31     1248\n",
      "5   2080 2019-01-01 2023-12-31     1248\n",
      "6   2280 2019-01-01 2023-12-31     1248\n",
      "7   2340 2019-01-01 2023-12-31     1248\n",
      "8   4004 2019-01-01 2023-12-31     1248\n",
      "9   4013 2019-01-01 2023-12-31     1248\n",
      "\n",
      "Total unique source dates in df: 1248\n",
      "Min/Max source date: 2019-01-01 00:00:00 -> 2023-12-31 00:00:00\n",
      "\n",
      "Unique pred_date count: 1247\n",
      "Min/Max pred_date: 2019-01-02 00:00:00 -> 2023-12-31 00:00:00\n",
      "\n",
      "First 5 (symbol, source date -> pred_date) rows:\n",
      "     symbol    التاريخ  pred_date\n",
      "7488   1140 2019-01-01 2019-01-02\n",
      "7489   1140 2019-01-02 2019-01-03\n",
      "7490   1140 2019-01-03 2019-01-06\n",
      "7491   1140 2019-01-06 2019-01-07\n",
      "7492   1140 2019-01-07 2019-01-08\n"
     ]
    }
   ],
   "source": [
    "# --- Diagnostics: check the pulled dataframe and dates BEFORE writing ---\n",
    "\n",
    "print(\"Total rows pulled from Firestore:\", len(df))\n",
    "print(\"Unique symbols:\", df[\"symbol\"].nunique())\n",
    "\n",
    "# how many unique raw dates per symbol from Firestore input:\n",
    "per_symbol = df.groupby(\"symbol\")[COL_DATE].agg([\"min\",\"max\",\"nunique\"]).reset_index()\n",
    "print(\"Sample per-symbol date stats:\")\n",
    "print(per_symbol.head(10))\n",
    "\n",
    "print(\"\\nTotal unique source dates in df:\", df[COL_DATE].nunique())\n",
    "print(\"Min/Max source date:\", df[COL_DATE].min(), \"->\", df[COL_DATE].max())\n",
    "\n",
    "# After building pred_date:\n",
    "tmp = df.sort_values([\"symbol\", COL_DATE]).copy()\n",
    "tmp[\"pred_date\"] = tmp.groupby(\"symbol\")[COL_DATE].shift(-1)\n",
    "# keep last-day inheritance the same way the writer does:\n",
    "mask_last = tmp[\"pred_date\"].isna()\n",
    "tmp.loc[mask_last, \"pred_date\"] = tmp.loc[mask_last, COL_DATE]\n",
    "\n",
    "print(\"\\nUnique pred_date count:\", tmp[\"pred_date\"].nunique())\n",
    "print(\"Min/Max pred_date:\", tmp[\"pred_date\"].min(), \"->\", tmp[\"pred_date\"].max())\n",
    "\n",
    "print(\"\\nFirst 5 (symbol, source date -> pred_date) rows:\")\n",
    "print(tmp[[\"symbol\", COL_DATE, \"pred_date\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "083e9aa3-e478-49b8-a5d6-36a840e7162d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found collection: Favorites\n",
      "Found collection: Learing\n",
      "Found collection: Portfolio\n",
      "Found collection: companies\n",
      "Found collection: market_predictions\n",
      "Found collection: market_predictions_daily\n",
      "Found collection: users\n"
     ]
    }
   ],
   "source": [
    "# list top-level collections\n",
    "for col in db.collections():\n",
    "    print(\"Found collection:\", col.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "982bb205-b508-4bc7-9d73-fb48aa86ef2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded model: out\\close_model_notrades.joblib\n",
      "Companies found: 20\n",
      "Pulled rows: 24960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asma5\\AppData\\Local\\Temp\\ipykernel_22268\\1552275963.py:132: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"decision\"].fillna(\"لا تشتري\", inplace=True)\n",
      "C:\\Users\\asma5\\AppData\\Local\\Temp\\ipykernel_22268\\1552275963.py:133: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"proba_buy\"].fillna(0.0, inplace=True)\n",
      "C:\\Users\\asma5\\AppData\\Local\\Temp\\ipykernel_22268\\1552275963.py:183: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now_iso = dt.datetime.utcnow().isoformat() + \"Z\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to write: 24960\n",
      "✅ Wrote 24960 docs into subcollections 'market_predictions_daily' under each company.\n"
     ]
    }
   ],
   "source": [
    "# ===================== Cell 7 — write predictions under companies/*/market_predictions_daily =====================\n",
    "import pandas as pd, numpy as np, datetime as dt, re\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "SERVICE_ACCOUNT_JSON = r\"nomu-47a92-firebase-adminsdk-fbsvc-1b2e28026c.json\"       # <-- change this\n",
    "MODEL_PATH           = Path(\"out/close_model_notrades.joblib\")    # or out/change_model_notrades.joblib\n",
    "\n",
    "COMPANIES_COLLECTION = \"companies\"\n",
    "PRICE_SUBCOLLECTION  = \"PriceRecords_full\"\n",
    "PRED_SUBCOLLECTION   = \"market_predictions_daily\"\n",
    "\n",
    "# Arabic column names used in training (NO trades model = 8 features)\n",
    "COL_SYMBOL   = \"رمز الشركة\"\n",
    "COL_NAME     = \"اسم الشركة\"\n",
    "COL_DATE     = \"التاريخ\"\n",
    "COL_OPEN     = \"إفتتاح\"\n",
    "COL_HIGH     = \"الأعلى\"\n",
    "COL_LOW      = \"الأدنى\"\n",
    "COL_CLOSE    = \"إقفال\"\n",
    "COL_CHANGE   = \"التغيير\"\n",
    "COL_PCT      = \"% التغيير\"\n",
    "COL_VOLUME   = \"الكمية المتداولة\"\n",
    "COL_TURNOVER = \"اجمالي القيمة المتداولة (ر.س)\"\n",
    "\n",
    "FEATURES = [COL_OPEN, COL_HIGH, COL_LOW, COL_CLOSE, COL_CHANGE, COL_PCT, COL_VOLUME, COL_TURNOVER]\n",
    "\n",
    "# Map Firestore raw fields -> our model columns\n",
    "FS_TO_MODEL = {\n",
    "    \"open\":        COL_OPEN,\n",
    "    \"high\":        COL_HIGH,\n",
    "    \"low\":         COL_LOW,\n",
    "    \"close\":       COL_CLOSE,\n",
    "    \"change\":      COL_CHANGE,\n",
    "    \"change_pct\":  COL_PCT,\n",
    "    \"volume\":      COL_VOLUME,\n",
    "    \"value\":       COL_TURNOVER,  # turnover SAR\n",
    "    \"date\":        COL_DATE,\n",
    "}\n",
    "\n",
    "def _norm_key(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = s.replace(\"إ\",\"ا\").replace(\"أ\",\"ا\").replace(\"آ\",\"ا\").replace(\"ٱ\",\"ا\").replace(\"ى\",\"ي\").replace(\"ة\",\"ه\")\n",
    "    return re.sub(r\"\\s+\", \"\", s).lower()\n",
    "\n",
    "def pick(d: dict, *cands, default=None):\n",
    "    \"\"\"Pick first existing key among candidates, with Arabic normalization fallback.\"\"\"\n",
    "    if not d: return default\n",
    "    for k in cands:\n",
    "        if k in d and d[k] is not None:\n",
    "            return d[k]\n",
    "    nd = { _norm_key(k): v for k, v in d.items() }\n",
    "    for k in cands:\n",
    "        nk = _norm_key(k)\n",
    "        if nk in nd and nd[nk] is not None:\n",
    "            return nd[nk]\n",
    "    return default\n",
    "\n",
    "# ---------- Firestore + model ----------\n",
    "if not firebase_admin._apps:\n",
    "    cred = credentials.Certificate(SERVICE_ACCOUNT_JSON)\n",
    "    firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n",
    "clf = joblib.load(MODEL_PATH)\n",
    "print(\"✅ Loaded model:\", MODEL_PATH)\n",
    "\n",
    "# ---------- Pull all companies and their price rows ----------\n",
    "rows = []\n",
    "companies = list(db.collection(COMPANIES_COLLECTION).stream())\n",
    "print(\"Companies found:\", len(companies))\n",
    "\n",
    "for comp in companies:\n",
    "    comp_id = comp.id\n",
    "    c = comp.to_dict() or {}\n",
    "    symbol = str(pick(c, \"id\", \"symbol\", COL_SYMBOL, default=comp_id)).strip()\n",
    "    name   = pick(c, \"name\", COL_NAME, default=comp_id)\n",
    "\n",
    "    price_ref = db.collection(COMPANIES_COLLECTION).document(comp_id).collection(PRICE_SUBCOLLECTION)\n",
    "    for rec in price_ref.stream():\n",
    "        d = rec.to_dict() or {}\n",
    "        row = {\"company_id\": comp_id, \"symbol\": symbol, \"company\": name}\n",
    "        for fs_key, model_key in FS_TO_MODEL.items():\n",
    "            row[model_key] = pick(d, fs_key, model_key)\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "if df.empty:\n",
    "    raise RuntimeError(\"No data found under companies/*/PriceRecords_full\")\n",
    "print(\"Pulled rows:\", len(df))\n",
    "\n",
    "# ---------- Types & cleaning ----------\n",
    "# If your stored dates are D/M/Y strings, add dayfirst=True\n",
    "df[COL_DATE] = pd.to_datetime(df[COL_DATE], errors=\"coerce\")  # , dayfirst=True\n",
    "\n",
    "for c in FEATURES:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df = df.dropna(subset=[COL_DATE, COL_CLOSE]).copy()\n",
    "df[\"symbol\"] = df[\"symbol\"].astype(str).str.strip()\n",
    "\n",
    "# Ensure all features exist\n",
    "fill_defaults = {\n",
    "    COL_OPEN: np.nan, COL_HIGH: np.nan, COL_LOW: np.nan, COL_CLOSE: np.nan,\n",
    "    COL_CHANGE: 0.0, COL_PCT: 0.0, COL_VOLUME: 0.0, COL_TURNOVER: 0.0\n",
    "}\n",
    "for f in FEATURES:\n",
    "    if f not in df.columns:\n",
    "        df[f] = fill_defaults.get(f, 0.0)\n",
    "\n",
    "# ---------- Predict for ALL days ----------\n",
    "df = df.sort_values([\"symbol\", COL_DATE]).copy()\n",
    "fill_map = {c: fill_defaults.get(c, 0.0) for c in FEATURES}\n",
    "X = df[FEATURES].fillna(fill_map).astype(np.float64).values\n",
    "\n",
    "proba = clf.predict_proba(X)\n",
    "buy_col = np.where(clf.classes_ == 1)[0][0]\n",
    "df[\"proba_buy\"] = proba[:, buy_col]\n",
    "df[\"decision\"]  = np.where(df[\"proba_buy\"] >= 0.5, \"اشتري\", \"لا تشتري\")\n",
    "\n",
    "# ---------- Next-day alignment, keep last day ----------\n",
    "df[\"pred_date\"] = df.groupby(\"symbol\")[COL_DATE].shift(-1)\n",
    "mask_last = df[\"pred_date\"].isna()\n",
    "df.loc[mask_last, \"pred_date\"] = df.loc[mask_last, COL_DATE]  # inherit tail\n",
    "df[\"decision\"]  = df.groupby(\"symbol\")[\"decision\"].ffill()\n",
    "df[\"proba_buy\"] = df.groupby(\"symbol\")[\"proba_buy\"].ffill()\n",
    "df[\"decision\"].fillna(\"لا تشتري\", inplace=True)\n",
    "df[\"proba_buy\"].fillna(0.0, inplace=True)\n",
    "\n",
    "# ---------- Build outgoing rows (next-day) ----------\n",
    "to_write = df[\n",
    "    [\"company_id\",\"symbol\",\"company\",\"pred_date\",\n",
    "     COL_OPEN, COL_HIGH, COL_LOW, COL_CLOSE, COL_CHANGE, COL_PCT,\n",
    "     \"proba_buy\",\"decision\"]\n",
    "].copy()\n",
    "\n",
    "to_write = to_write.rename(columns={\n",
    "    \"pred_date\": \"date\",\n",
    "    COL_OPEN: \"open\", COL_HIGH: \"high\", COL_LOW: \"low\",\n",
    "    COL_CLOSE:\"close\", COL_CHANGE:\"change\", COL_PCT:\"pct_change\"\n",
    "})\n",
    "\n",
    "# ---------- PAD FIRST DAY using NEXT day's decision ----------\n",
    "# 1) first price row per symbol (day1 fields)\n",
    "first_prices = (\n",
    "    df.sort_values([\"symbol\", COL_DATE])\n",
    "      .groupby(\"symbol\", as_index=False)\n",
    "      .first()[[\"company_id\",\"symbol\",\"company\", COL_DATE,\n",
    "                COL_OPEN, COL_HIGH, COL_LOW, COL_CLOSE, COL_CHANGE, COL_PCT]]\n",
    "      .rename(columns={COL_DATE: \"date\",\n",
    "                       COL_OPEN:\"open\", COL_HIGH:\"high\", COL_LOW:\"low\",\n",
    "                       COL_CLOSE:\"close\", COL_CHANGE:\"change\", COL_PCT:\"pct_change\"})\n",
    ")\n",
    "\n",
    "# 2) earliest available prediction per symbol (this is for day2)\n",
    "earliest_pred = (\n",
    "    to_write.sort_values([\"symbol\",\"date\"])\n",
    "            .groupby(\"symbol\", as_index=False)\n",
    "            .first()[[\"symbol\",\"proba_buy\",\"decision\"]]\n",
    ")\n",
    "\n",
    "# 3) join → first-day rows with next-day decision\n",
    "first_pad = first_prices.merge(earliest_pred, on=\"symbol\", how=\"left\")\n",
    "first_pad = first_pad[[\n",
    "    \"company_id\",\"symbol\",\"company\",\"date\",\n",
    "    \"open\",\"high\",\"low\",\"close\",\"change\",\"pct_change\",\n",
    "    \"proba_buy\",\"decision\"\n",
    "]]\n",
    "\n",
    "# 4) append & drop any accidental duplicates on (symbol,date)\n",
    "to_write = pd.concat([to_write, first_pad], ignore_index=True)\n",
    "to_write = (to_write.sort_values([\"symbol\",\"date\"])\n",
    "                    .drop_duplicates(subset=[\"symbol\",\"date\"], keep=\"first\"))\n",
    "\n",
    "print(\"Rows to write:\", len(to_write))\n",
    "\n",
    "# ---------- WRITE to companies/{companyId}/market_predictions_daily/{YYYY-MM-DD} ----------\n",
    "now_iso = dt.datetime.utcnow().isoformat() + \"Z\"\n",
    "BATCH_LIMIT = 500\n",
    "written = 0\n",
    "\n",
    "for comp_id, g in to_write.groupby(\"company_id\"):\n",
    "    batch = db.batch()\n",
    "    ops = 0\n",
    "\n",
    "    company_doc = db.collection(COMPANIES_COLLECTION).document(comp_id)\n",
    "    pred_col = company_doc.collection(PRED_SUBCOLLECTION)\n",
    "\n",
    "    for _, r in g.iterrows():\n",
    "        date_str = pd.to_datetime(r[\"date\"]).date().isoformat()\n",
    "        doc_ref = pred_col.document(date_str)\n",
    "\n",
    "        payload = {\n",
    "            \"symbol\": str(r[\"symbol\"]).strip(),\n",
    "            \"company\": r[\"company\"],\n",
    "            \"date\": date_str,               # YYYY-MM-DD (the day the decision applies to)\n",
    "            \"open\":  float(r[\"open\"])  if pd.notnull(r[\"open\"])  else None,\n",
    "            \"high\":  float(r[\"high\"])  if pd.notnull(r[\"high\"])  else None,\n",
    "            \"low\":   float(r[\"low\"])   if pd.notnull(r[\"low\"])   else None,\n",
    "            \"close\": float(r[\"close\"]) if pd.notnull(r[\"close\"]) else None,\n",
    "            \"change\":     float(r[\"change\"])     if pd.notnull(r[\"change\"])     else None,\n",
    "            \"pct_change\": float(r[\"pct_change\"]) if pd.notnull(r[\"pct_change\"]) else None,\n",
    "            \"proba_buy\": float(r[\"proba_buy\"]) if pd.notnull(r[\"proba_buy\"]) else None,\n",
    "            \"decision\": r[\"decision\"],\n",
    "            \"updatedAt\": now_iso,\n",
    "        }\n",
    "\n",
    "        batch.set(doc_ref, payload, merge=True)\n",
    "        ops += 1\n",
    "        written += 1\n",
    "\n",
    "        if ops >= BATCH_LIMIT:\n",
    "            batch.commit()\n",
    "            batch = db.batch()\n",
    "            ops = 0\n",
    "\n",
    "    if ops:\n",
    "        batch.commit()\n",
    "\n",
    "print(f\"✅ Wrote {written} docs into subcollections '{PRED_SUBCOLLECTION}' under each company.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b567806d-38c6-4bc1-8ad2-75be40b75a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asma5\\AppData\\Local\\Temp\\ipykernel_22268\\1126431747.py:33: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(str(v), errors=\"coerce\", dayfirst=True).date()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4013] الشركة السعودية للخدمات الأرضية → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[2010] الشركة السعودية للصناعات الأساسية → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[2070] الشركة السعودية للصناعات الدوائية والمستلزمات الطبية → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[8190] الشركة المتحدة للتأمين التعاوني → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[4030] الشركة الوطنية السعودية للنقل البحري → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[4210] المجموعة السعودية للأبحاث والإعلام → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[1140] بنك البلاد → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[2340] شركة ارتيكس للاستثمار الصناعي → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[7010] شركة الإتصالات السعودية → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[2080] شركة الغاز والتصنيع الأهلية → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[2280] شركة المراعي → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[4170] شركة المشروعات السياحية → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[4160] شركة ثمار التنمية القابضة → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[4190] شركة جرير للتسويق → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[4300] شركة دار الاركان للتطوير العقاري → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[4004] شركة دله للخدمات الصحية → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[6004] شركة كاتريون للتموين القابضة → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[4347] صندوق بنيان ريت → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[1212] مجموعة استرا الصناعية → price=1248 / pred=1248 | missing=0 extra=0\n",
      "[1810] مجموعة سيرا القابضة → price=1248 / pred=1248 | missing=0 extra=0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_doc_id</th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>price_dates</th>\n",
       "      <th>pred_dates</th>\n",
       "      <th>missing_in_predictions</th>\n",
       "      <th>extra_in_predictions</th>\n",
       "      <th>missing_examples</th>\n",
       "      <th>extra_examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بنك البلاد</td>\n",
       "      <td>1140</td>\n",
       "      <td>بنك البلاد</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>مجموعة استرا الصناعية</td>\n",
       "      <td>1212</td>\n",
       "      <td>مجموعة استرا الصناعية</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>مجموعة سيرا القابضة</td>\n",
       "      <td>1810</td>\n",
       "      <td>مجموعة سيرا القابضة</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>الشركة السعودية للصناعات الاساسية</td>\n",
       "      <td>2010</td>\n",
       "      <td>الشركة السعودية للصناعات الأساسية</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الشركة السعودية للصناعات الدوائية والمستلزمات ...</td>\n",
       "      <td>2070</td>\n",
       "      <td>الشركة السعودية للصناعات الدوائية والمستلزمات ...</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>شركة الغاز والتصنيع الاهلية</td>\n",
       "      <td>2080</td>\n",
       "      <td>شركة الغاز والتصنيع الأهلية</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>شركة المراعي</td>\n",
       "      <td>2280</td>\n",
       "      <td>شركة المراعي</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>شركة ارتيكس للاستثمار الصناعي</td>\n",
       "      <td>2340</td>\n",
       "      <td>شركة ارتيكس للاستثمار الصناعي</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>شركة دله للخدمات الصحية</td>\n",
       "      <td>4004</td>\n",
       "      <td>شركة دله للخدمات الصحية</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>الشركة السعودية للخدمات الارضية</td>\n",
       "      <td>4013</td>\n",
       "      <td>الشركة السعودية للخدمات الأرضية</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>الشركة الوطنية السعودية للنقل البحري</td>\n",
       "      <td>4030</td>\n",
       "      <td>الشركة الوطنية السعودية للنقل البحري</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>شركة ثمار التنمية القابضة</td>\n",
       "      <td>4160</td>\n",
       "      <td>شركة ثمار التنمية القابضة</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>شركة المشروعات السياحية</td>\n",
       "      <td>4170</td>\n",
       "      <td>شركة المشروعات السياحية</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>شركة جرير للتسويق</td>\n",
       "      <td>4190</td>\n",
       "      <td>شركة جرير للتسويق</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>المجموعة السعودية للابحاث والاعلام</td>\n",
       "      <td>4210</td>\n",
       "      <td>المجموعة السعودية للأبحاث والإعلام</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>شركة دار الاركان للتطوير العقاري</td>\n",
       "      <td>4300</td>\n",
       "      <td>شركة دار الاركان للتطوير العقاري</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>صندوق بنيان ريت</td>\n",
       "      <td>4347</td>\n",
       "      <td>صندوق بنيان ريت</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>شركة كاتريون للتموين القابضة</td>\n",
       "      <td>6004</td>\n",
       "      <td>شركة كاتريون للتموين القابضة</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>شركة الاتصالات السعودية</td>\n",
       "      <td>7010</td>\n",
       "      <td>شركة الإتصالات السعودية</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>الشركة المتحدة للتامين التعاوني</td>\n",
       "      <td>8190</td>\n",
       "      <td>الشركة المتحدة للتأمين التعاوني</td>\n",
       "      <td>1248</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       company_doc_id symbol  \\\n",
       "0                                          بنك البلاد   1140   \n",
       "1                               مجموعة استرا الصناعية   1212   \n",
       "2                                 مجموعة سيرا القابضة   1810   \n",
       "3                   الشركة السعودية للصناعات الاساسية   2010   \n",
       "4   الشركة السعودية للصناعات الدوائية والمستلزمات ...   2070   \n",
       "5                         شركة الغاز والتصنيع الاهلية   2080   \n",
       "6                                        شركة المراعي   2280   \n",
       "7                       شركة ارتيكس للاستثمار الصناعي   2340   \n",
       "8                             شركة دله للخدمات الصحية   4004   \n",
       "9                     الشركة السعودية للخدمات الارضية   4013   \n",
       "10               الشركة الوطنية السعودية للنقل البحري   4030   \n",
       "11                          شركة ثمار التنمية القابضة   4160   \n",
       "12                            شركة المشروعات السياحية   4170   \n",
       "13                                  شركة جرير للتسويق   4190   \n",
       "14                 المجموعة السعودية للابحاث والاعلام   4210   \n",
       "15                   شركة دار الاركان للتطوير العقاري   4300   \n",
       "16                                    صندوق بنيان ريت   4347   \n",
       "17                       شركة كاتريون للتموين القابضة   6004   \n",
       "18                            شركة الاتصالات السعودية   7010   \n",
       "19                    الشركة المتحدة للتامين التعاوني   8190   \n",
       "\n",
       "                                                 name  price_dates  \\\n",
       "0                                          بنك البلاد         1248   \n",
       "1                               مجموعة استرا الصناعية         1248   \n",
       "2                                 مجموعة سيرا القابضة         1248   \n",
       "3                   الشركة السعودية للصناعات الأساسية         1248   \n",
       "4   الشركة السعودية للصناعات الدوائية والمستلزمات ...         1248   \n",
       "5                         شركة الغاز والتصنيع الأهلية         1248   \n",
       "6                                        شركة المراعي         1248   \n",
       "7                       شركة ارتيكس للاستثمار الصناعي         1248   \n",
       "8                             شركة دله للخدمات الصحية         1248   \n",
       "9                     الشركة السعودية للخدمات الأرضية         1248   \n",
       "10               الشركة الوطنية السعودية للنقل البحري         1248   \n",
       "11                          شركة ثمار التنمية القابضة         1248   \n",
       "12                            شركة المشروعات السياحية         1248   \n",
       "13                                  شركة جرير للتسويق         1248   \n",
       "14                 المجموعة السعودية للأبحاث والإعلام         1248   \n",
       "15                   شركة دار الاركان للتطوير العقاري         1248   \n",
       "16                                    صندوق بنيان ريت         1248   \n",
       "17                       شركة كاتريون للتموين القابضة         1248   \n",
       "18                            شركة الإتصالات السعودية         1248   \n",
       "19                    الشركة المتحدة للتأمين التعاوني         1248   \n",
       "\n",
       "    pred_dates  missing_in_predictions  extra_in_predictions missing_examples  \\\n",
       "0         1248                       0                     0                    \n",
       "1         1248                       0                     0                    \n",
       "2         1248                       0                     0                    \n",
       "3         1248                       0                     0                    \n",
       "4         1248                       0                     0                    \n",
       "5         1248                       0                     0                    \n",
       "6         1248                       0                     0                    \n",
       "7         1248                       0                     0                    \n",
       "8         1248                       0                     0                    \n",
       "9         1248                       0                     0                    \n",
       "10        1248                       0                     0                    \n",
       "11        1248                       0                     0                    \n",
       "12        1248                       0                     0                    \n",
       "13        1248                       0                     0                    \n",
       "14        1248                       0                     0                    \n",
       "15        1248                       0                     0                    \n",
       "16        1248                       0                     0                    \n",
       "17        1248                       0                     0                    \n",
       "18        1248                       0                     0                    \n",
       "19        1248                       0                     0                    \n",
       "\n",
       "   extra_examples  \n",
       "0                  \n",
       "1                  \n",
       "2                  \n",
       "3                  \n",
       "4                  \n",
       "5                  \n",
       "6                  \n",
       "7                  \n",
       "8                  \n",
       "9                  \n",
       "10                 \n",
       "11                 \n",
       "12                 \n",
       "13                 \n",
       "14                 \n",
       "15                 \n",
       "16                 \n",
       "17                 \n",
       "18                 \n",
       "19                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Saved detailed report to: parity_report.csv\n",
      "✅ Parity check PASSED: prediction dates match price dates for all companies.\n"
     ]
    }
   ],
   "source": [
    "# ===================== Cell 8 — Parity checker (PriceRecords_full vs market_predictions_daily) =====================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from typing import Any\n",
    "\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore\n",
    "\n",
    "# --- config ---\n",
    "SERVICE_ACCOUNT_JSON = r\"nomu-47a92-firebase-adminsdk-fbsvc-1b2e28026c.json\"  # <-- edit if needed\n",
    "COMPANIES_COLLECTION = \"companies\"\n",
    "PRICE_SUBCOLLECTION  = \"PriceRecords_full\"\n",
    "PRED_SUBCOLLECTION   = \"market_predictions_daily\"\n",
    "\n",
    "def to_date_only(v: Any) -> dt.date | None:\n",
    "    \"\"\"Normalize Firestore values to date (YYYY-MM-DD). Accepts str, Timestamp, datetime, etc.\"\"\"\n",
    "    if v is None:\n",
    "        return None\n",
    "    # Firestore Timestamp has .to_datetime()\n",
    "    if hasattr(v, \"to_datetime\"):\n",
    "        try:\n",
    "            return v.to_datetime().date()\n",
    "        except Exception:\n",
    "            pass\n",
    "    # python datetime / date\n",
    "    if isinstance(v, dt.datetime):\n",
    "        return v.date()\n",
    "    if isinstance(v, dt.date):\n",
    "        return v\n",
    "    # string -> parse\n",
    "    try:\n",
    "        return pd.to_datetime(str(v), errors=\"coerce\", dayfirst=True).date()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# init firestore\n",
    "if not firebase_admin._apps:\n",
    "    cred = credentials.Certificate(SERVICE_ACCOUNT_JSON)\n",
    "    firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n",
    "companies = list(db.collection(COMPANIES_COLLECTION).stream())\n",
    "print(\"Companies:\", len(companies))\n",
    "\n",
    "rows = []\n",
    "total_only_in_price = 0\n",
    "total_only_in_pred  = 0\n",
    "\n",
    "for comp in companies:\n",
    "    comp_id = comp.id\n",
    "    data = comp.to_dict() or {}\n",
    "    name  = data.get(\"name\", comp_id)\n",
    "    symbol = str(data.get(\"symbol\", data.get(\"id\", comp_id)))\n",
    "\n",
    "    # --- collect dates from PriceRecords_full (source of truth) ---\n",
    "    A = set()\n",
    "    price_ref = db.collection(COMPANIES_COLLECTION).document(comp_id).collection(PRICE_SUBCOLLECTION)\n",
    "    for doc in price_ref.stream():\n",
    "        d = doc.to_dict() or {}\n",
    "        date_val = d.get(\"date\", None)\n",
    "        dd = to_date_only(date_val)\n",
    "        if dd: A.add(dd)\n",
    "\n",
    "    # --- collect dates from market_predictions_daily ---\n",
    "    B = set()\n",
    "    pred_ref = db.collection(COMPANIES_COLLECTION).document(comp_id).collection(PRED_SUBCOLLECTION)\n",
    "    for doc in pred_ref.stream():\n",
    "        d = doc.to_dict() or {}\n",
    "        date_val = d.get(\"date\", None)\n",
    "        dd = to_date_only(date_val)\n",
    "        # fallback: if field missing, try doc id\n",
    "        if dd is None:\n",
    "            dd = to_date_only(doc.id)\n",
    "        if dd: B.add(dd)\n",
    "\n",
    "    only_in_price = sorted(A - B)\n",
    "    only_in_pred  = sorted(B - A)\n",
    "\n",
    "    total_only_in_price += len(only_in_price)\n",
    "    total_only_in_pred  += len(only_in_pred)\n",
    "\n",
    "    rows.append({\n",
    "        \"company_doc_id\": comp_id,\n",
    "        \"symbol\": symbol,\n",
    "        \"name\": name,\n",
    "        \"price_dates\": len(A),\n",
    "        \"pred_dates\": len(B),\n",
    "        \"missing_in_predictions\": len(only_in_price),\n",
    "        \"extra_in_predictions\": len(only_in_pred),\n",
    "        \"missing_examples\": \", \".join(map(str, only_in_price[:5])),\n",
    "        \"extra_examples\": \", \".join(map(str, only_in_pred[:5])),\n",
    "    })\n",
    "\n",
    "    # per-company console summary\n",
    "    print(\n",
    "        f\"[{symbol}] {name} → price={len(A)} / pred={len(B)} | \"\n",
    "        f\"missing={len(only_in_price)} extra={len(only_in_pred)}\"\n",
    "        + (f\" | missing ex: {', '.join(map(str, only_in_price[:3]))}\" if only_in_price else \"\")\n",
    "        + (f\" | extra ex: {', '.join(map(str, only_in_pred[:3]))}\" if only_in_pred else \"\")\n",
    "    )\n",
    "\n",
    "report = pd.DataFrame(rows).sort_values([\"missing_in_predictions\",\"extra_in_predictions\",\"symbol\"], ascending=[False, False, True]).reset_index(drop=True)\n",
    "display(report)\n",
    "\n",
    "csv_path = \"parity_report.csv\"\n",
    "report.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"\\n✅ Saved detailed report to:\", csv_path)\n",
    "\n",
    "if total_only_in_price == 0 and total_only_in_pred == 0:\n",
    "    print(\"✅ Parity check PASSED: prediction dates match price dates for all companies.\")\n",
    "else:\n",
    "    print(f\"⚠️ Parity differences found: missing_total={total_only_in_price}, extra_total={total_only_in_pred}\")\n",
    "    print(\"   → See 'parity_report.csv' for details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dcde01-5123-4bd5-a836-cb316c188dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
