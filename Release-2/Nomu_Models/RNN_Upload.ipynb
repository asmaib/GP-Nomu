{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8abc2e58-c328-4849-9064-9fd44879bc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asma5\\AppData\\Local\\Temp\\ipykernel_17068\\4061115701.py:39: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  wide = wide.applymap(to_float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (98200, 20, 1) (98200,)\n",
      "Test : (24600, 20, 1) (24600,)\n",
      "WARNING:tensorflow:From C:\\Users\\asma5\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Epoch 1/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - loss: 0.0302 - val_loss: 0.1460\n",
      "Epoch 2/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - loss: 0.0108 - val_loss: 0.1173\n",
      "Epoch 3/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0094 - val_loss: 0.0892\n",
      "Epoch 4/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 0.0092 - val_loss: 0.0887\n",
      "Epoch 5/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 0.0090 - val_loss: 0.0781\n",
      "Epoch 6/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 0.0089 - val_loss: 0.0674\n",
      "Epoch 7/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 0.0089 - val_loss: 0.0897\n",
      "Epoch 8/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 0.0088 - val_loss: 0.0618\n",
      "Epoch 9/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 0.0087 - val_loss: 0.0763\n",
      "Epoch 10/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 0.0086 - val_loss: 0.0837\n",
      "Epoch 11/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 0.0085 - val_loss: 0.0607\n",
      "Epoch 12/12\n",
      "\u001b[1m768/768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - loss: 0.0086 - val_loss: 0.0707\n",
      "\n",
      "=== Global Test Metrics ===\n",
      "R²   = 0.9959\n",
      "MAE  = 0.8247\n",
      "RMSE = 2.7179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample predictions with recommendations:\n",
      "                                اسم الشركة  yesterday   predicted  \\\n",
      "0                 اعمار المدينة الاقتصادية      17.23   17.257523   \n",
      "1                     البنك الاهلي السعودي      38.65   38.840885   \n",
      "2                      البنك السعودي الاول      37.90   37.912212   \n",
      "3                    البنك السعودي الفرنسي      19.30   19.340147   \n",
      "4                  البنك السعودي للاستثمار      12.76   12.740829   \n",
      "5                      البنك العربي الوطني      18.97   18.995378   \n",
      "6                 الشركة التعاونية للتامين     130.20  106.493378   \n",
      "7  الشركة الخليجية العامة للتامين التعاوني      13.17   13.307072   \n",
      "8           الشركة السعودية لاعادة التامين      18.60   18.536388   \n",
      "9            الشركة السعودية لانابيب الصلب      36.30   35.888721   \n",
      "\n",
      "  recommendation  \n",
      "0      Don’t Buy  \n",
      "1      Don’t Buy  \n",
      "2      Don’t Buy  \n",
      "3      Don’t Buy  \n",
      "4            Buy  \n",
      "5      Don’t Buy  \n",
      "6            Buy  \n",
      "7      Don’t Buy  \n",
      "8            Buy  \n",
      "9            Buy  \n",
      "✅ Saved model: out\\rnn_model_with_norm.h5\n",
      "✅ Saved recommendations: out\\rnn_recommendations.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# -------- إعدادات --------\n",
    "WIDE_PATH   = \"Equites_Close_Daily.csv\"   # ملف wide (كل عمود = يوم)\n",
    "WINDOW_LEN  = 20\n",
    "TRAIN_RATIO = 0.8\n",
    "EPOCHS      = 12\n",
    "BATCH_SIZE  = 128\n",
    "\n",
    "# -------- دوال --------\n",
    "def to_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def build_sequences(series_vals, window):\n",
    "    X, y = [], []\n",
    "    for t in range(window, len(series_vals)):\n",
    "        feat = series_vals[t-window:t]\n",
    "        target = series_vals[t]\n",
    "        if np.isnan(feat).any() or np.isnan(target):\n",
    "            continue\n",
    "        X.append(feat)\n",
    "        y.append(target)\n",
    "    if not X:\n",
    "        return np.empty((0, window, 1)), np.empty((0,))\n",
    "    X = np.array(X, dtype=\"float32\")[:, :, None]\n",
    "    y = np.array(y, dtype=\"float32\")\n",
    "    return X, y\n",
    "\n",
    "# -------- تحميل الملف --------\n",
    "wide = pd.read_csv(WIDE_PATH, encoding=\"utf-8-sig\").set_index(\"اسم الشركة\")\n",
    "wide = wide.applymap(to_float)\n",
    "\n",
    "# -------- إعداد بيانات التدريب --------\n",
    "X_tr_list, y_tr_list = [], []\n",
    "X_te_list, y_te_list = [], []\n",
    "te_mu_list, te_sigma_list = [], []\n",
    "next_day_preds = []\n",
    "\n",
    "for comp, row in wide.iterrows():\n",
    "    vals = row.values.astype(\"float64\")\n",
    "    if np.sum(~np.isnan(vals)) < WINDOW_LEN + 2:\n",
    "        continue\n",
    "\n",
    "    X_all, y_all = build_sequences(vals, WINDOW_LEN)\n",
    "    if len(y_all) < 3:\n",
    "        continue\n",
    "\n",
    "    split = max(1, int(len(y_all) * TRAIN_RATIO))\n",
    "    X_tr_c, y_tr_c = X_all[:split], y_all[:split]\n",
    "    X_te_c, y_te_c = X_all[split:], y_all[split:]\n",
    "    if len(y_te_c) == 0:\n",
    "        continue\n",
    "\n",
    "    # تطبيع based على train\n",
    "    train_series_vals = np.concatenate([X_tr_c.reshape(-1), y_tr_c.reshape(-1)])\n",
    "    mu = np.nanmean(train_series_vals)\n",
    "    sigma = np.nanstd(train_series_vals)\n",
    "    if not np.isfinite(mu) or sigma <= 1e-12:\n",
    "        continue\n",
    "\n",
    "    X_tr_c_norm = (X_tr_c - mu) / sigma\n",
    "    y_tr_c_norm = (y_tr_c - mu) / sigma\n",
    "    X_te_c_norm = (X_te_c - mu) / sigma\n",
    "    y_te_c_norm = (y_te_c - mu) / sigma\n",
    "\n",
    "    X_tr_list.append(X_tr_c_norm)\n",
    "    y_tr_list.append(y_tr_c_norm)\n",
    "    X_te_list.append(X_te_c_norm)\n",
    "    y_te_list.append(y_te_c_norm)\n",
    "\n",
    "    te_mu_list += [mu] * len(y_te_c_norm)\n",
    "    te_sigma_list += [sigma] * len(y_te_c_norm)\n",
    "\n",
    "    # آخر نافذة للتنبؤ\n",
    "    last_window_raw = vals[-WINDOW_LEN:]\n",
    "    if np.isnan(last_window_raw).any():\n",
    "        next_day_preds.append({\"اسم الشركة\": comp, \"next_day_pred\": np.nan})\n",
    "    else:\n",
    "        last_window_norm = ((last_window_raw - mu) / sigma).astype(\"float32\").reshape(1, WINDOW_LEN, 1)\n",
    "        next_day_preds.append({\n",
    "            \"اسم الشركة\": comp,\n",
    "            \"last_window_norm\": last_window_norm,\n",
    "            \"mu\": mu,\n",
    "            \"sigma\": sigma,\n",
    "            \"yesterday\": last_window_raw[-1]\n",
    "        })\n",
    "\n",
    "# دمج\n",
    "X_train = np.concatenate(X_tr_list, axis=0)\n",
    "y_train = np.concatenate(y_tr_list, axis=0)\n",
    "X_test  = np.concatenate(X_te_list, axis=0)\n",
    "y_test  = np.concatenate(y_te_list, axis=0)\n",
    "te_mu   = np.array(te_mu_list, dtype=\"float64\")\n",
    "te_sig  = np.array(te_sigma_list, dtype=\"float64\")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test :\", X_test.shape,  y_test.shape)\n",
    "\n",
    "# -------- RNN --------\n",
    "tf.keras.backend.clear_session()\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(WINDOW_LEN, 1)),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.LSTM(32),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# -------- تقييم --------\n",
    "y_hat_norm = model.predict(X_test, verbose=0).reshape(-1)\n",
    "y_hat = y_hat_norm * te_sig + te_mu\n",
    "y_true = y_test * te_sig + te_mu\n",
    "\n",
    "R2   = r2_score(y_true, y_hat)\n",
    "MAE  = mean_absolute_error(y_true, y_hat)\n",
    "RMSE = float(np.sqrt(mean_squared_error(y_true, y_hat)))\n",
    "\n",
    "print(\"\\n=== Global Test Metrics ===\")\n",
    "print(f\"R²   = {R2:.4f}\")\n",
    "print(f\"MAE  = {MAE:.4f}\")\n",
    "print(f\"RMSE = {RMSE:.4f}\")\n",
    "\n",
    "# -------- توقع + توصية --------\n",
    "pred_rows = []\n",
    "for rec in next_day_preds:\n",
    "    comp = rec[\"اسم الشركة\"]\n",
    "    if \"last_window_norm\" not in rec:\n",
    "        pred_rows.append({\"اسم الشركة\": comp, \"yesterday\": np.nan, \"predicted\": np.nan, \"recommendation\": \"N/A\"})\n",
    "        continue\n",
    "    pred_norm = model.predict(rec[\"last_window_norm\"], verbose=0).reshape(-1)[0]\n",
    "    pred = pred_norm * rec[\"sigma\"] + rec[\"mu\"]\n",
    "    yesterday = rec[\"yesterday\"]\n",
    "    recommendation = \"Buy\" if pred < yesterday else \"Don’t Buy\"\n",
    "    pred_rows.append({\n",
    "        \"اسم الشركة\": comp,\n",
    "        \"yesterday\": float(yesterday),\n",
    "        \"predicted\": float(pred),\n",
    "        \"recommendation\": recommendation\n",
    "    })\n",
    "\n",
    "pred_df = pd.DataFrame(pred_rows)\n",
    "print(\"\\nSample predictions with recommendations:\")\n",
    "print(pred_df.head(10))\n",
    "\n",
    "import os\n",
    "\n",
    "# -------- مجلد الحفظ --------\n",
    "OUT_DIR = \"out\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)   # ينشئ مجلد out إذا لم يكن موجودًا\n",
    "\n",
    "# -------- حفظ الموديل --------\n",
    "model_path = os.path.join(OUT_DIR, \"rnn_model_with_norm.h5\")\n",
    "model.save(model_path)\n",
    "print(f\"✅ Saved model: {model_path}\")\n",
    "\n",
    "# -------- حفظ النتائج --------\n",
    "csv_path = os.path.join(OUT_DIR, \"rnn_recommendations.csv\")\n",
    "pred_df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✅ Saved recommendations: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60d345d-e61a-408f-bb14-08be68f53b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded Keras H5 model: out\\rnn_model_with_norm.h5\n",
      "Model input shape: (None, 20, 1)\n",
      "Model output shape: (None, 1)\n"
     ]
    }
   ],
   "source": [
    "# ===================== Cell 1 — Init + Load RNN =====================\n",
    "import os, re, math\n",
    "import pandas as pd, numpy as np, datetime as dt\n",
    "from pathlib import Path\n",
    "\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# --- CONFIG ---\n",
    "SERVICE_ACCOUNT_JSON = r\"nomu-47a92-firebase-adminsdk-fbsvc-1b2e28026c.json\"   # <-- change path if needed\n",
    "MODEL_PATH           = Path(\"out/rnn_model_with_norm.h5\")   # <-- this is a Keras H5 model\n",
    "COMPANIES_COLLECTION = \"companies\"\n",
    "PRICE_SUBCOLLECTION  = \"PriceRecords_full\"\n",
    "PRED_SUBCOLLECTION   = \"market_predictions_daily\"\n",
    "WINDOW_LEN           = 20\n",
    "\n",
    "# --- Firestore init ---\n",
    "if not firebase_admin._apps:\n",
    "    cred = credentials.Certificate(SERVICE_ACCOUNT_JSON)\n",
    "    firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n",
    "# --- Load Keras RNN (.h5) ---\n",
    "model = load_model(str(MODEL_PATH), compile=False)\n",
    "print(\"✅ Loaded Keras H5 model:\", MODEL_PATH)\n",
    "print(\"Model input shape:\", model.input_shape)\n",
    "print(\"Model output shape:\", model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b2b864-600c-46bd-b95c-f3ce351eea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Cell 2 — Helpers =====================\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np\n",
    "\n",
    "def to_float(x):\n",
    "    try:\n",
    "        if isinstance(x, str):\n",
    "            x = x.replace(\",\", \"\")\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def parse_date(val):\n",
    "    if hasattr(val, \"to_datetime\"):  # Firestore Timestamp\n",
    "        return val.to_datetime()\n",
    "    if isinstance(val, datetime):\n",
    "        return val\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            return datetime.fromisoformat(val)\n",
    "        except Exception:\n",
    "            return datetime.strptime(val, \"%Y-%m-%d\")\n",
    "    return datetime.now(timezone.utc)\n",
    "\n",
    "def build_sequences(series_vals, window=WINDOW_LEN):\n",
    "    X, y = [], []\n",
    "    for t in range(window, len(series_vals)):\n",
    "        feat = series_vals[t-window:t]\n",
    "        target = series_vals[t]\n",
    "        if np.isnan(feat).any() or np.isnan(target):\n",
    "            continue\n",
    "        X.append(feat)\n",
    "        y.append(target)\n",
    "    if not X:\n",
    "        return np.empty((0, window, 1)), np.empty((0,))\n",
    "    X = np.array(X, dtype=\"float32\")[:, :, None]\n",
    "    y = np.array(y, dtype=\"float32\")\n",
    "    return X, y\n",
    "\n",
    "def predict_next_close(window_vals):\n",
    "    \"\"\"Normalize, run model.predict(), denormalize prediction.\"\"\"\n",
    "    arr = np.array(window_vals, dtype=\"float32\")\n",
    "    mu, sigma = np.mean(arr), np.std(arr)\n",
    "    if not np.isfinite(mu) or sigma <= 1e-12:\n",
    "        return np.nan\n",
    "\n",
    "    # normalize window\n",
    "    x = ((arr - mu) / sigma).astype(\"float32\").reshape(1, WINDOW_LEN, 1)\n",
    "\n",
    "    # use Keras model\n",
    "    pred_norm = model.predict(x, verbose=0).reshape(-1)[0]\n",
    "\n",
    "    # denormalize back\n",
    "    return float(pred_norm * sigma + mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "589d850b-963d-420c-9cf9-5c4d2c556fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies found: 20\n",
      "Predictions generated: 24560\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>date</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>predicted</th>\n",
       "      <th>recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الشركة السعودية للخدمات الارضية</td>\n",
       "      <td>2019-01-29</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>30.871824</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الشركة السعودية للخدمات الارضية</td>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>30.799999</td>\n",
       "      <td>30.783920</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>الشركة السعودية للخدمات الارضية</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>30.850000</td>\n",
       "      <td>30.836943</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>الشركة السعودية للخدمات الارضية</td>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>30.900000</td>\n",
       "      <td>30.891821</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الشركة السعودية للخدمات الارضية</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>31.111467</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        company_id        date  yesterday  predicted  \\\n",
       "0  الشركة السعودية للخدمات الارضية  2019-01-29  30.950001  30.871824   \n",
       "1  الشركة السعودية للخدمات الارضية  2019-01-30  30.799999  30.783920   \n",
       "2  الشركة السعودية للخدمات الارضية  2019-01-31  30.850000  30.836943   \n",
       "3  الشركة السعودية للخدمات الارضية  2019-02-03  30.900000  30.891821   \n",
       "4  الشركة السعودية للخدمات الارضية  2019-02-04  31.250000  31.111467   \n",
       "\n",
       "  recommendation  \n",
       "0            Buy  \n",
       "1            Buy  \n",
       "2            Buy  \n",
       "3            Buy  \n",
       "4            Buy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===================== Cell 3 — Predict all companies =====================\n",
    "companies = list(db.collection(COMPANIES_COLLECTION).stream())\n",
    "print(\"Companies found:\", len(companies))\n",
    "\n",
    "rows = []\n",
    "for comp in companies:\n",
    "    comp_id = comp.id\n",
    "    price_ref = db.collection(COMPANIES_COLLECTION).document(comp_id).collection(PRICE_SUBCOLLECTION)\n",
    "    recs = list(price_ref.stream())\n",
    "\n",
    "    if not recs:\n",
    "        continue\n",
    "\n",
    "    # extract closes ordered by date\n",
    "    tmp = []\n",
    "    for r in recs:\n",
    "        d = r.to_dict() or {}\n",
    "        dt_ = parse_date(d.get(\"date\"))\n",
    "        close = to_float(d.get(\"close\"))\n",
    "        tmp.append((dt_, close))\n",
    "    tmp.sort(key=lambda x: x[0])\n",
    "    dates, closes = zip(*tmp)\n",
    "\n",
    "    closes = np.array(closes, dtype=\"float32\")\n",
    "\n",
    "    # build sliding windows\n",
    "    X_all, y_all = build_sequences(closes, WINDOW_LEN)\n",
    "\n",
    "    if len(X_all) == 0:\n",
    "        continue\n",
    "\n",
    "    # run predictions for each window\n",
    "    preds = []\n",
    "    for i in range(len(X_all)):\n",
    "        pred_val = predict_next_close(closes[i:i+WINDOW_LEN])\n",
    "        preds.append(pred_val)\n",
    "\n",
    "    # align with target dates\n",
    "    pred_dates = dates[WINDOW_LEN:]  # prediction aligns to t+1 day\n",
    "    for d, yest, pred in zip(pred_dates, closes[WINDOW_LEN-1:-1], preds):\n",
    "        recommendation = \"Buy\" if pred < yest else \"Don’t Buy\"\n",
    "        rows.append({\n",
    "            \"company_id\": comp_id,\n",
    "            \"date\": d.date().isoformat(),\n",
    "            \"yesterday\": float(yest),\n",
    "            \"predicted\": float(pred),\n",
    "            \"recommendation\": recommendation\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Predictions generated:\", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "653c69b1-6f70-4d8a-bb20-8b6da60acc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asma5\\AppData\\Local\\Temp\\ipykernel_17068\\3160227969.py:2: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now_iso = dt.datetime.utcnow().isoformat() + \"Z\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote 24560 docs into subcollections 'market_predictions_daily' under each company.\n"
     ]
    }
   ],
   "source": [
    "# ===================== Cell 4 — Write to Firestore =====================\n",
    "now_iso = dt.datetime.utcnow().isoformat() + \"Z\"\n",
    "BATCH_LIMIT = 500\n",
    "written = 0\n",
    "\n",
    "for comp_id, g in df.groupby(\"company_id\"):\n",
    "    batch = db.batch()\n",
    "    ops = 0\n",
    "\n",
    "    company_doc = db.collection(COMPANIES_COLLECTION).document(comp_id)\n",
    "    pred_col = company_doc.collection(PRED_SUBCOLLECTION)\n",
    "\n",
    "    for _, r in g.iterrows():\n",
    "        doc_ref = pred_col.document(r[\"date\"])   # YYYY-MM-DD\n",
    "        payload = {\n",
    "            \"yesterday\": r[\"yesterday\"],\n",
    "            \"predicted\": r[\"predicted\"],\n",
    "            \"recommendation\": r[\"recommendation\"],\n",
    "            \"updatedAt\": now_iso,\n",
    "        }\n",
    "        batch.set(doc_ref, payload, merge=True)\n",
    "        ops += 1\n",
    "        written += 1\n",
    "\n",
    "        if ops >= BATCH_LIMIT:\n",
    "            batch.commit()\n",
    "            batch = db.batch()\n",
    "            ops = 0\n",
    "\n",
    "    if ops:\n",
    "        batch.commit()\n",
    "\n",
    "print(f\"✅ Wrote {written} docs into subcollections '{PRED_SUBCOLLECTION}' under each company.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5202007-3130-454f-8e4f-f7117c18e4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions: 24560\n",
      "Unique companies: 20\n",
      "Sample rows:\n",
      "                        company_id        date  yesterday  predicted  \\\n",
      "0  الشركة السعودية للخدمات الارضية  2019-01-29  30.950001  30.871824   \n",
      "1  الشركة السعودية للخدمات الارضية  2019-01-30  30.799999  30.783920   \n",
      "2  الشركة السعودية للخدمات الارضية  2019-01-31  30.850000  30.836943   \n",
      "3  الشركة السعودية للخدمات الارضية  2019-02-03  30.900000  30.891821   \n",
      "4  الشركة السعودية للخدمات الارضية  2019-02-04  31.250000  31.111467   \n",
      "5  الشركة السعودية للخدمات الارضية  2019-02-05  31.250000  31.277872   \n",
      "6  الشركة السعودية للخدمات الارضية  2019-02-06  31.250000  31.213934   \n",
      "7  الشركة السعودية للخدمات الارضية  2019-02-07  31.200001  31.162630   \n",
      "8  الشركة السعودية للخدمات الارضية  2019-02-10  31.049999  31.012804   \n",
      "9  الشركة السعودية للخدمات الارضية  2019-02-11  31.049999  31.033693   \n",
      "\n",
      "  recommendation  \n",
      "0            Buy  \n",
      "1            Buy  \n",
      "2            Buy  \n",
      "3            Buy  \n",
      "4            Buy  \n",
      "5      Don’t Buy  \n",
      "6            Buy  \n",
      "7            Buy  \n",
      "8            Buy  \n",
      "9            Buy  \n"
     ]
    }
   ],
   "source": [
    "# ===================== Cell 5 — Diagnostics =====================\n",
    "print(\"Total predictions:\", len(df))\n",
    "print(\"Unique companies:\", df[\"company_id\"].nunique())\n",
    "print(\"Sample rows:\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff8a895-0741-46e3-9eb6-f1e2b6cdae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Cell 3 — Predict all companies (no missing dates, PAD=inherit, Arabic recs) =====================\n",
    "PAD_STRATEGY = \"inherit\"   # \"inherit\" or \"na\"\n",
    "\n",
    "companies = list(db.collection(COMPANIES_COLLECTION).stream())\n",
    "print(\"Companies found:\", len(companies))\n",
    "\n",
    "rows = []\n",
    "for comp in companies:\n",
    "    comp_id = comp.id\n",
    "    price_ref = (\n",
    "        db.collection(COMPANIES_COLLECTION)\n",
    "          .document(comp_id)\n",
    "          .collection(PRICE_SUBCOLLECTION)\n",
    "    )\n",
    "    recs = list(price_ref.stream())\n",
    "    if not recs:\n",
    "        continue\n",
    "\n",
    "    # extract closes ordered by date\n",
    "    tmp = []\n",
    "    for r in recs:\n",
    "        d = r.to_dict() or {}\n",
    "        dt_ = parse_date(d.get(\"date\"))\n",
    "        close = to_float(d.get(\"close\"))\n",
    "        tmp.append((dt_, close))\n",
    "    tmp.sort(key=lambda x: x[0])\n",
    "\n",
    "    dates, closes = zip(*tmp)  # tuples\n",
    "    closes = np.array(closes, dtype=\"float32\")\n",
    "    N = len(closes)\n",
    "\n",
    "    # Predict for all windows (N - WINDOW_LEN)\n",
    "    preds = [np.nan] * max(0, N - WINDOW_LEN)\n",
    "    first_pred = np.nan\n",
    "\n",
    "    if N >= WINDOW_LEN:\n",
    "        window_preds = []\n",
    "        for i in range(N - WINDOW_LEN):\n",
    "            pv = predict_next_close(closes[i:i+WINDOW_LEN])\n",
    "            window_preds.append(pv)\n",
    "        preds = window_preds\n",
    "        if len(window_preds) > 0 and np.isfinite(window_preds[0]):\n",
    "            first_pred = float(window_preds[0])\n",
    "\n",
    "    # Emit exactly one row PER DATE (length N)\n",
    "    for idx in range(N):\n",
    "        # normalize date to YYYY-MM-DD\n",
    "        if hasattr(dates[idx], \"date\"):\n",
    "            date_iso = dates[idx].date().isoformat()\n",
    "        else:\n",
    "            date_iso = pd.to_datetime(dates[idx]).date().isoformat()\n",
    "\n",
    "        # yesterday for idx>0\n",
    "        yesterday_val = float(closes[idx-1]) if idx > 0 and np.isfinite(closes[idx-1]) else None\n",
    "\n",
    "        if idx < WINDOW_LEN:\n",
    "            # padding zone (no window yet)\n",
    "            if PAD_STRATEGY == \"inherit\" and np.isfinite(first_pred):\n",
    "                predicted_val = first_pred\n",
    "                if yesterday_val is None or not np.isfinite(yesterday_val):\n",
    "                    recommendation = \"N/A\"\n",
    "                else:\n",
    "                    recommendation = \"اشتري\" if predicted_val < yesterday_val else \"لا تشتري\"\n",
    "            else:\n",
    "                predicted_val = None\n",
    "                recommendation = \"N/A\"\n",
    "        else:\n",
    "            # normal predicted row aligned so pred(t) uses window ending at t-1\n",
    "            p = preds[idx - WINDOW_LEN]\n",
    "            predicted_val = float(p) if np.isfinite(p) else None\n",
    "            if yesterday_val is None or not np.isfinite(yesterday_val) or predicted_val is None:\n",
    "                recommendation = \"N/A\"\n",
    "            else:\n",
    "                recommendation = \"اشتري\" if predicted_val < yesterday_val else \"لا تشتري\"\n",
    "\n",
    "        rows.append({\n",
    "            \"company_id\": comp_id,\n",
    "            \"date\": date_iso,\n",
    "            \"yesterday\": yesterday_val if (yesterday_val is None or np.isfinite(yesterday_val)) else None,\n",
    "            \"predicted\": predicted_val,\n",
    "            \"recommendation\": recommendation\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Predictions generated (should equal total price rows):\", len(df))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b217c02-4ae9-45fa-8fb8-43a7a5642648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Firestore ready for project: nomu-47a92\n"
     ]
    }
   ],
   "source": [
    "# === Cell 0: init key + project (Firebase Admin) ===\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore as fb_firestore\n",
    "\n",
    "KEY_PATH = r\"nomu-47a92-firebase-adminsdk-fbsvc-1b2e28026c.json\"  # ← مسار ملف المفتاح الصحيح\n",
    "PROJECT_ID = \"nomu-47a92\"                                         # ← اسم مشروعك الحقيقي\n",
    "\n",
    "# لو فيه db قديم بمشروع placeholder نزله من الذاكرة\n",
    "try:\n",
    "    del db\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# ابدأ Firebase Admin باستخدام ملف المفتاح\n",
    "if not firebase_admin._apps:\n",
    "    cred = credentials.Certificate(KEY_PATH)\n",
    "    firebase_admin.initialize_app(cred, {\"projectId\": PROJECT_ID})\n",
    "\n",
    "# أنشئ عميل فايرستور من Firebase Admin (مو من google-cloud مباشرة)\n",
    "db = fb_firestore.client()\n",
    "\n",
    "print(\"✅ Firestore ready for project:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91e775fe-9419-4bb2-939c-7800bfcbff29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists: True\n",
      "Doc path: companies/بنك البلاد\n"
     ]
    }
   ],
   "source": [
    "# === Cell 1: quick access test ===\n",
    "COMPANIES_COLLECTION = \"companies\"\n",
    "doc_id = \"بنك البلاد\"  # تأكد أنه بالضبط نفس الـ document id في قاعدة بياناتك\n",
    "\n",
    "ref = db.collection(COMPANIES_COLLECTION).document(doc_id)\n",
    "snap = ref.get()\n",
    "print(\"Exists:\", snap.exists)\n",
    "print(\"Doc path:\", ref.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a924cc3-812e-42ac-8300-365a26805016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم حذف 'recommendation' من 1228 مستند في بنك البلاد.\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: delete recommendation for ONE company ===\n",
    "from firebase_admin import firestore as fb_firestore\n",
    "\n",
    "PRED_SUBCOLLECTION = \"market_predictions_daily\"\n",
    "test_company_id = \"بنك البلاد\"  # غيّرها حسب ما تريد اختباره\n",
    "\n",
    "pred_col = db.collection(COMPANIES_COLLECTION).document(test_company_id).collection(PRED_SUBCOLLECTION)\n",
    "batch = db.batch()\n",
    "ops = 0\n",
    "touched = 0\n",
    "\n",
    "for doc in pred_col.stream():\n",
    "    batch.update(doc.reference, {\"recommendation\": fb_firestore.DELETE_FIELD})\n",
    "    ops += 1\n",
    "    touched += 1\n",
    "    if ops >= 500:\n",
    "        batch.commit()\n",
    "        batch = db.batch()\n",
    "        ops = 0\n",
    "\n",
    "if ops:\n",
    "    batch.commit()\n",
    "\n",
    "print(f\"✅ تم حذف 'recommendation' من {touched} مستند في {test_company_id}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af8bc4e7-a23c-4590-8c3e-c864aa837a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تم حذف حقل 'recommendation' من 24560 مستند عبر جميع الشركات.\n"
     ]
    }
   ],
   "source": [
    "# === Cell 3: full sweep (all companies) ===\n",
    "from firebase_admin import firestore as fb_firestore\n",
    "\n",
    "COMPANIES_COLLECTION = \"companies\"\n",
    "PRED_SUBCOLLECTION  = \"market_predictions_daily\"\n",
    "\n",
    "BATCH_LIMIT = 500\n",
    "ops = 0\n",
    "touched = 0\n",
    "batch = db.batch()\n",
    "\n",
    "companies = db.collection(COMPANIES_COLLECTION).stream()\n",
    "\n",
    "for company in companies:\n",
    "    pred_col = db.collection(COMPANIES_COLLECTION).document(company.id).collection(PRED_SUBCOLLECTION)\n",
    "    for doc in pred_col.stream():\n",
    "        batch.update(doc.reference, {\"recommendation\": fb_firestore.DELETE_FIELD})\n",
    "        ops += 1\n",
    "        touched += 1\n",
    "\n",
    "        if ops >= BATCH_LIMIT:\n",
    "            batch.commit()\n",
    "            batch = db.batch()\n",
    "            ops = 0\n",
    "\n",
    "if ops:\n",
    "    batch.commit()\n",
    "\n",
    "print(f\"✅ تم حذف حقل 'recommendation' من {touched} مستند عبر جميع الشركات.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba2a3d3-5b52-4d78-8c9a-1723ce4d9a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
